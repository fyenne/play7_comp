{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# first in receipt prediction on multiple targets, fas data set "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib  \n",
                "import seaborn as sns\n",
                "import plotly.express as px\n",
                "import plotly.graph_objs as go\n",
                "from plotly.tools import FigureFactory as FF\n",
                "import re\n",
                "import os\n",
                "from datetime import datetime, timedelta\n",
                "os.getcwd()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 179,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Internal_Receipt_num</th>\n",
                            "      <th>warehouse</th>\n",
                            "      <th>company</th>\n",
                            "      <th>receipt_id</th>\n",
                            "      <th>receipt_date</th>\n",
                            "      <th>CLOSE_DATE</th>\n",
                            "      <th>ARRIVED_DATE_TIME</th>\n",
                            "      <th>CREATION_DATE_TIME_STAMP</th>\n",
                            "      <th>total_lines</th>\n",
                            "      <th>TOTAL_QTY</th>\n",
                            "      <th>TOTAL_CONTAINERS</th>\n",
                            "      <th>TOTAL_WEIGHT</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>12347</td>\n",
                            "      <td>FAS</td>\n",
                            "      <td>Pernod</td>\n",
                            "      <td>20170914 CHANGE CODE-3</td>\n",
                            "      <td>2017-09-14 00:00:00.000</td>\n",
                            "      <td>2017-09-14 09:43:55.010</td>\n",
                            "      <td>2017-09-14 09:41:22.000</td>\n",
                            "      <td>2017-09-14 01:40:13.000</td>\n",
                            "      <td>1</td>\n",
                            "      <td>150.0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>200.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>12348</td>\n",
                            "      <td>FAS</td>\n",
                            "      <td>Solvay-SHANGHAI</td>\n",
                            "      <td>CHANGEPLANT170914-1</td>\n",
                            "      <td>2017-09-14 00:00:00.000</td>\n",
                            "      <td>2017-09-14 10:03:17.010</td>\n",
                            "      <td>2017-09-14 10:00:46.000</td>\n",
                            "      <td>2017-09-14 01:51:28.000</td>\n",
                            "      <td>9</td>\n",
                            "      <td>12.0</td>\n",
                            "      <td>9</td>\n",
                            "      <td>300.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>12346</td>\n",
                            "      <td>FAS</td>\n",
                            "      <td>Solvay-SHANGHAI</td>\n",
                            "      <td>CHANGEPLANT170914</td>\n",
                            "      <td>2017-09-14 00:00:00.000</td>\n",
                            "      <td>2017-09-14 10:03:18.533</td>\n",
                            "      <td>2017-09-14 09:47:38.000</td>\n",
                            "      <td>2017-09-14 01:36:58.000</td>\n",
                            "      <td>10</td>\n",
                            "      <td>12.0</td>\n",
                            "      <td>10</td>\n",
                            "      <td>300.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   Internal_Receipt_num warehouse          company              receipt_id  \\\n",
                            "0                 12347       FAS           Pernod  20170914 CHANGE CODE-3   \n",
                            "1                 12348       FAS  Solvay-SHANGHAI     CHANGEPLANT170914-1   \n",
                            "2                 12346       FAS  Solvay-SHANGHAI       CHANGEPLANT170914   \n",
                            "\n",
                            "              receipt_date               CLOSE_DATE        ARRIVED_DATE_TIME  \\\n",
                            "0  2017-09-14 00:00:00.000  2017-09-14 09:43:55.010  2017-09-14 09:41:22.000   \n",
                            "1  2017-09-14 00:00:00.000  2017-09-14 10:03:17.010  2017-09-14 10:00:46.000   \n",
                            "2  2017-09-14 00:00:00.000  2017-09-14 10:03:18.533  2017-09-14 09:47:38.000   \n",
                            "\n",
                            "  CREATION_DATE_TIME_STAMP  total_lines  TOTAL_QTY  TOTAL_CONTAINERS  \\\n",
                            "0  2017-09-14 01:40:13.000            1      150.0                 1   \n",
                            "1  2017-09-14 01:51:28.000            9       12.0                 9   \n",
                            "2  2017-09-14 01:36:58.000           10       12.0                10   \n",
                            "\n",
                            "   TOTAL_WEIGHT  \n",
                            "0         200.0  \n",
                            "1         300.0  \n",
                            "2         300.0  "
                        ]
                    },
                    "execution_count": 179,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# df = pd.read_clipboard()\n",
                "# df.to_csv('./fas_057_rh.csv', index = False, encoding='utf_8_sig')\n",
                "df = pd.read_csv('./fas_057_rh.csv')\n",
                "df = df.fillna(method = 'ffill')\n",
                "df_test = pd.read_csv('./fas_inbhdr_test.csv')\n",
                "df_test = df_test.fillna(method = 'ffill')\n",
                "# df_test.columns = [re.sub(r'.+\\.','',i) for i in df_test.columns]\n",
                "df_test = df_test[df_test['RECEIPT_DATE'] > '2021-05-10']\n",
                "\n",
                "\n",
                "\n",
                "df_loc_inv = pd.read_csv('./location_inv.csv')\n",
                "[str(datetime.strptime(i, '%Y-%m-%d %H:%M:%S.%f')-timedelta(days = 1)) for i in df_loc_inv['RECEIVED_DATE']];\n",
                "df_loc_inv.head(3)\n",
                "# df=df.drop(['RECEIPT_DATE','RECEIPT_DATE_TIME'], axis  = 1 )\n",
                "df.head(3)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 180,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.columns = [i.upper() for i in df.columns.to_numpy()]\n",
                "df_test.columns = [i.upper() for i in df_test.columns.to_numpy()]\n",
                "\n",
                "def date_mutate(col, df):\n",
                "    df[col] = [(datetime.strptime(i,'%Y-%m-%d %H:%M:%S.%f')+timedelta(hours = 8)) for i in df[col]]\n",
                "    df[col + '_TIME'] = df[col].apply(lambda x : x.strftime('%H%M%S'))\n",
                "    df[col] = df[col].apply(lambda x : x.strftime('%Y%m%d'))\n",
                "    df[col+ '_2'] = df[col + '_TIME']\n",
                "    # df[col + '_2'] = [datetime.strptime(i,'%H:%M:%S.%f').strftime('%H%M%S') \\\n",
                "    #     for i in df[col + '_TIME']]\n",
                "    return df.head(1)\n",
                "\n",
                "for i in df.columns[df.columns.str.contains(r'date|DATE')].to_numpy():\n",
                "    date_mutate(i, df)\n",
                "\n",
                "for i in df_test.columns[df_test.columns.str.contains(r'date|DATE')].to_numpy():\n",
                "    date_mutate(i, df_test)\n",
                "\n",
                "\n",
                "\n",
                "def firstdata(df):\n",
                "    first_df = df.groupby(\n",
                "        'CREATION_DATE_TIME_STAMP', as_index = False\n",
                "        )['CREATION_DATE_TIME_STAMP'].min().reset_index()\n",
                "    first_df = first_df.merge(\n",
                "        df, \n",
                "        on = ['CREATION_DATE_TIME_STAMP'], \n",
                "        how = 'inner')\n",
                "    return first_df\n",
                "\n",
                "first_df = firstdata(df)\n",
                "df_test_first = firstdata(df_test)\n",
                "\n",
                " \n",
                "\n",
                "date_mutate('RECEIVED_DATE', df_loc_inv)\n",
                "\n",
                "\n",
                "df_loc_inv_lag = (df_loc_inv[df_loc_inv['RECEIVED_DATE'] > '20170910']\\\n",
                "    .groupby('RECEIVED_DATE').sum().reset_index()).merge(df_loc_inv[['RECEIVED_DATE', 'RECEIVED_DATE_TIME',\n",
                "       'RECEIVED_DATE_2']].groupby('RECEIVED_DATE').first(), on = 'RECEIVED_DATE', how = 'left')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 217,
            "metadata": {},
            "outputs": [],
            "source": [
                "def data_mani(first_df, df):\n",
                "    train_first = first_df.groupby(\n",
                "        'CREATION_DATE_TIME_STAMP'\n",
                "        ).agg({'RECEIPT_ID':['nunique'], \n",
                "        'TOTAL_LINES': ['sum'], \n",
                "        'TOTAL_CONTAINERS': 'sum', \n",
                "        'TOTAL_WEIGHT':'sum',\n",
                "        'TOTAL_QTY': ['sum'],\n",
                "        'CREATION_DATE_TIME_STAMP_2': 'min' }).reset_index()\n",
                "        \n",
                "    train_full = df.groupby(\n",
                "        'CREATION_DATE_TIME_STAMP'\n",
                "        ).agg({'RECEIPT_ID':['nunique'], \n",
                "        'TOTAL_LINES': ['sum'], \n",
                "        'TOTAL_CONTAINERS': 'sum', \n",
                "        'TOTAL_WEIGHT':'sum',\n",
                "        'TOTAL_QTY': ['sum'],\n",
                "        'CREATION_DATE_TIME_STAMP_2': 'max' }).reset_index()\n",
                "\n",
                "    train_full.columns = ['CREATION_DATE_TIME_STAMP','id', 'line_sum', 'container_sum', 'weight', 'qty', 'creat_time']\n",
                "    train_first.columns = ['CREATION_DATE_TIME_STAMP','id', 'line_sum', 'container_sum', 'weight', 'qty', 'creat_time']\n",
                "\n",
                "    train_first.index= pd.to_datetime(train_first['CREATION_DATE_TIME_STAMP'], \\\n",
                "        yearfirst = True,  format='%Y-%m-%d')\n",
                "    train_full.index = train_full['CREATION_DATE_TIME_STAMP']\n",
                "    train_full.index = pd.DatetimeIndex(train_full.index)\n",
                "\n",
                "    train_full['CREATION_DATE_TIME_STAMP'] = pd.to_datetime(train_full['CREATION_DATE_TIME_STAMP'])\n",
                "    train_first['CREATION_DATE_TIME_STAMP'] = pd.to_datetime(train_first['CREATION_DATE_TIME_STAMP'])\n",
                "    return train_first  , train_full \n",
                "\n",
                "\n",
                "train_first, train_full = data_mani(first_df, df)\n",
                "test_first, test_full = data_mani(df_test_first, df_test)\n",
                "train_first = train_first.reset_index(drop = True)\n",
                "test_first = test_first.reset_index(drop = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 218,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>CREATION_DATE_TIME_STAMP</th>\n",
                            "      <th>id</th>\n",
                            "      <th>line_sum</th>\n",
                            "      <th>container_sum</th>\n",
                            "      <th>weight</th>\n",
                            "      <th>qty</th>\n",
                            "      <th>creat_time</th>\n",
                            "      <th>ON_HAND_QTY</th>\n",
                            "      <th>TOTAL_VALUE</th>\n",
                            "      <th>TOTAL_COST</th>\n",
                            "      <th>TOTAL_WEIGHT</th>\n",
                            "      <th>TOTAL_VOLUME</th>\n",
                            "      <th>RECEIVED_DATE_TIME</th>\n",
                            "      <th>RECEIVED_DATE_2</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2017-09-11</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>22</td>\n",
                            "      <td>22000.00</td>\n",
                            "      <td>880.0</td>\n",
                            "      <td>112456</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2017-09-12</td>\n",
                            "      <td>9</td>\n",
                            "      <td>30</td>\n",
                            "      <td>96</td>\n",
                            "      <td>850242.84</td>\n",
                            "      <td>512046.0</td>\n",
                            "      <td>130737</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2017-09-13</td>\n",
                            "      <td>6</td>\n",
                            "      <td>9</td>\n",
                            "      <td>41</td>\n",
                            "      <td>41290.00</td>\n",
                            "      <td>1778.0</td>\n",
                            "      <td>092211</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2017-09-14</td>\n",
                            "      <td>11</td>\n",
                            "      <td>49</td>\n",
                            "      <td>140</td>\n",
                            "      <td>121620.00</td>\n",
                            "      <td>16690.0</td>\n",
                            "      <td>082402</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2017-09-15</td>\n",
                            "      <td>4</td>\n",
                            "      <td>16</td>\n",
                            "      <td>36</td>\n",
                            "      <td>96619.20</td>\n",
                            "      <td>93797.0</td>\n",
                            "      <td>094709</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>881</th>\n",
                            "      <td>2021-04-25</td>\n",
                            "      <td>6</td>\n",
                            "      <td>9</td>\n",
                            "      <td>55</td>\n",
                            "      <td>113837.57</td>\n",
                            "      <td>92622.0</td>\n",
                            "      <td>155955</td>\n",
                            "      <td>39478.0</td>\n",
                            "      <td>164995.38</td>\n",
                            "      <td>1.077237e+06</td>\n",
                            "      <td>315630.20</td>\n",
                            "      <td>4.583909e+08</td>\n",
                            "      <td>083236</td>\n",
                            "      <td>083236</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>882</th>\n",
                            "      <td>2021-04-28</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>3</td>\n",
                            "      <td>1290.24</td>\n",
                            "      <td>1008.0</td>\n",
                            "      <td>133557</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>883</th>\n",
                            "      <td>2021-04-29</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>10</td>\n",
                            "      <td>12516.00</td>\n",
                            "      <td>10080.0</td>\n",
                            "      <td>131023</td>\n",
                            "      <td>18.0</td>\n",
                            "      <td>81.00</td>\n",
                            "      <td>2.091652e+03</td>\n",
                            "      <td>179.64</td>\n",
                            "      <td>3.021975e+05</td>\n",
                            "      <td>164536</td>\n",
                            "      <td>164536</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>884</th>\n",
                            "      <td>2021-04-30</td>\n",
                            "      <td>6</td>\n",
                            "      <td>7</td>\n",
                            "      <td>26</td>\n",
                            "      <td>116677.30</td>\n",
                            "      <td>127932.0</td>\n",
                            "      <td>125253</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>885</th>\n",
                            "      <td>2021-05-07</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>17</td>\n",
                            "      <td>9292.50</td>\n",
                            "      <td>5400.0</td>\n",
                            "      <td>164451</td>\n",
                            "      <td>11930.0</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.000000e+00</td>\n",
                            "      <td>148809.90</td>\n",
                            "      <td>2.644420e+08</td>\n",
                            "      <td>100330</td>\n",
                            "      <td>100330</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>886 rows × 14 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    CREATION_DATE_TIME_STAMP  id  line_sum  container_sum     weight  \\\n",
                            "0                 2017-09-11   1         2             22   22000.00   \n",
                            "1                 2017-09-12   9        30             96  850242.84   \n",
                            "2                 2017-09-13   6         9             41   41290.00   \n",
                            "3                 2017-09-14  11        49            140  121620.00   \n",
                            "4                 2017-09-15   4        16             36   96619.20   \n",
                            "..                       ...  ..       ...            ...        ...   \n",
                            "881               2021-04-25   6         9             55  113837.57   \n",
                            "882               2021-04-28   1         2              3    1290.24   \n",
                            "883               2021-04-29   1         1             10   12516.00   \n",
                            "884               2021-04-30   6         7             26  116677.30   \n",
                            "885               2021-05-07   1         2             17    9292.50   \n",
                            "\n",
                            "          qty creat_time  ON_HAND_QTY  TOTAL_VALUE    TOTAL_COST  \\\n",
                            "0       880.0     112456          NaN          NaN           NaN   \n",
                            "1    512046.0     130737          NaN          NaN           NaN   \n",
                            "2      1778.0     092211          NaN          NaN           NaN   \n",
                            "3     16690.0     082402          NaN          NaN           NaN   \n",
                            "4     93797.0     094709          NaN          NaN           NaN   \n",
                            "..        ...        ...          ...          ...           ...   \n",
                            "881   92622.0     155955      39478.0    164995.38  1.077237e+06   \n",
                            "882    1008.0     133557          NaN          NaN           NaN   \n",
                            "883   10080.0     131023         18.0        81.00  2.091652e+03   \n",
                            "884  127932.0     125253          NaN          NaN           NaN   \n",
                            "885    5400.0     164451      11930.0         0.00  0.000000e+00   \n",
                            "\n",
                            "     TOTAL_WEIGHT  TOTAL_VOLUME RECEIVED_DATE_TIME RECEIVED_DATE_2  \n",
                            "0             NaN           NaN                NaN             NaN  \n",
                            "1             NaN           NaN                NaN             NaN  \n",
                            "2             NaN           NaN                NaN             NaN  \n",
                            "3             NaN           NaN                NaN             NaN  \n",
                            "4             NaN           NaN                NaN             NaN  \n",
                            "..            ...           ...                ...             ...  \n",
                            "881     315630.20  4.583909e+08             083236          083236  \n",
                            "882           NaN           NaN                NaN             NaN  \n",
                            "883        179.64  3.021975e+05             164536          164536  \n",
                            "884           NaN           NaN                NaN             NaN  \n",
                            "885     148809.90  2.644420e+08             100330          100330  \n",
                            "\n",
                            "[886 rows x 14 columns]"
                        ]
                    },
                    "execution_count": 218,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_loc_inv_lag['RECEIVED_DATE'] = pd.to_datetime(df_loc_inv_lag['RECEIVED_DATE'])\n",
                "# df_loc_inv_lag\n",
                "train_first = train_first.merge(df_loc_inv_lag, left_on='CREATION_DATE_TIME_STAMP', right_on = 'RECEIVED_DATE', how = 'left')\n",
                "# sns.scatterplot(x = 'container_sum', y  ='qty', color = 'red' , data = train_full)\n",
                "train_first = train_first.drop('RECEIVED_DATE', axis =  1); train_first"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 219,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "CREATION_DATE_TIME_STAMP      0\n",
                            "id                            0\n",
                            "line_sum                      0\n",
                            "container_sum                 0\n",
                            "weight                        0\n",
                            "qty                           0\n",
                            "creat_time                    0\n",
                            "ON_HAND_QTY                 411\n",
                            "TOTAL_VALUE                 411\n",
                            "TOTAL_COST                  411\n",
                            "TOTAL_WEIGHT                411\n",
                            "TOTAL_VOLUME                411\n",
                            "RECEIVED_DATE_TIME          411\n",
                            "RECEIVED_DATE_2             411\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 219,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_first.isnull().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 220,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.impute import SimpleImputer,  KNNImputer\n",
                "from sklearn.preprocessing import StandardScaler \n",
                "train_first.iloc[:, 7:] = pd.DataFrame(\n",
                "    KNNImputer(n_neighbors=12, weights=\"uniform\").fit_transform(train_first.iloc[:, 7:])\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 229,
            "metadata": {},
            "outputs": [],
            "source": [
                "# sns.histplot(train_full['qty'],color = 'red' )\n",
                "ss = StandardScaler()\n",
                "table = pd.DataFrame()\n",
                "for i in train_first.columns[7:]:\n",
                "    table[[i]] = ss.fit_transform(train_first[[i]]) \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 230,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>ON_HAND_QTY</th>\n",
                            "      <th>TOTAL_VALUE</th>\n",
                            "      <th>TOTAL_COST</th>\n",
                            "      <th>TOTAL_WEIGHT</th>\n",
                            "      <th>TOTAL_VOLUME</th>\n",
                            "      <th>RECEIVED_DATE_TIME</th>\n",
                            "      <th>RECEIVED_DATE_2</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>5.217960e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-5.697863e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-6.708675e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>5.217960e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-5.697863e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-6.708675e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>5.217960e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-5.697863e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-6.708675e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>5.217960e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-5.697863e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-6.708675e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5.217960e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-5.697863e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-6.708675e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>881</th>\n",
                            "      <td>4.135769e+00</td>\n",
                            "      <td>9.608758</td>\n",
                            "      <td>7.968366e+00</td>\n",
                            "      <td>3.694609</td>\n",
                            "      <td>3.678614e+00</td>\n",
                            "      <td>-1.346746</td>\n",
                            "      <td>-1.346746</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>882</th>\n",
                            "      <td>5.217960e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-5.697863e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-6.708675e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>883</th>\n",
                            "      <td>-3.920354e-01</td>\n",
                            "      <td>-0.372168</td>\n",
                            "      <td>-4.511829e-01</td>\n",
                            "      <td>-0.435116</td>\n",
                            "      <td>-4.461224e-01</td>\n",
                            "      <td>2.150838</td>\n",
                            "      <td>2.150838</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>884</th>\n",
                            "      <td>5.217960e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-5.697863e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>-6.708675e-17</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>885</th>\n",
                            "      <td>9.747971e-01</td>\n",
                            "      <td>-0.377070</td>\n",
                            "      <td>-4.675628e-01</td>\n",
                            "      <td>1.510679</td>\n",
                            "      <td>1.932254e+00</td>\n",
                            "      <td>-0.611350</td>\n",
                            "      <td>-0.611350</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>886 rows × 7 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      ON_HAND_QTY  TOTAL_VALUE    TOTAL_COST  TOTAL_WEIGHT  TOTAL_VOLUME  \\\n",
                            "0    5.217960e-17     0.000000 -5.697863e-17      0.000000 -6.708675e-17   \n",
                            "1    5.217960e-17     0.000000 -5.697863e-17      0.000000 -6.708675e-17   \n",
                            "2    5.217960e-17     0.000000 -5.697863e-17      0.000000 -6.708675e-17   \n",
                            "3    5.217960e-17     0.000000 -5.697863e-17      0.000000 -6.708675e-17   \n",
                            "4    5.217960e-17     0.000000 -5.697863e-17      0.000000 -6.708675e-17   \n",
                            "..            ...          ...           ...           ...           ...   \n",
                            "881  4.135769e+00     9.608758  7.968366e+00      3.694609  3.678614e+00   \n",
                            "882  5.217960e-17     0.000000 -5.697863e-17      0.000000 -6.708675e-17   \n",
                            "883 -3.920354e-01    -0.372168 -4.511829e-01     -0.435116 -4.461224e-01   \n",
                            "884  5.217960e-17     0.000000 -5.697863e-17      0.000000 -6.708675e-17   \n",
                            "885  9.747971e-01    -0.377070 -4.675628e-01      1.510679  1.932254e+00   \n",
                            "\n",
                            "     RECEIVED_DATE_TIME  RECEIVED_DATE_2  \n",
                            "0              0.000000         0.000000  \n",
                            "1              0.000000         0.000000  \n",
                            "2              0.000000         0.000000  \n",
                            "3              0.000000         0.000000  \n",
                            "4              0.000000         0.000000  \n",
                            "..                  ...              ...  \n",
                            "881           -1.346746        -1.346746  \n",
                            "882            0.000000         0.000000  \n",
                            "883            2.150838         2.150838  \n",
                            "884            0.000000         0.000000  \n",
                            "885           -0.611350        -0.611350  \n",
                            "\n",
                            "[886 rows x 7 columns]"
                        ]
                    },
                    "execution_count": 230,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "table# 少他妈的一半数字, 不想做了.. 傻逼\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## deal with outbound data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ob_train = pd.read_csv('./outb_fas.csv', parse_dates=['date'])\n",
                "# ob_train = ob_train.dropna(how = 'all', axis = 1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train_first.index= pd.to_datetime(train_first['CREATION_DATE_TIME_STAMP'], yearfirst = True,  format='%Y-%m-%d')\n",
                "# train_first.pop('CREATION_DATE_TIME_STAMP')\n",
                "# train_full.pop('CREATION_DATE_TIME_STAMP')\n",
                "# train_full['qty'] = train_full['qty'].astype(int)\n",
                "# train_first['qty'] = train_first['qty'].astype(int)\n",
                "# train_first['qty2'] = train_full['qty'].to_numpy() ; train_first\n",
                "\n",
                "# train_first = train_first.reset_index()\n",
                "# train_first.drop(['qty2','CREATION_DATE_TIME_STAMP','creat_time'], axis =1) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# sktime; timeseries only prediction on trainfull\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train_full.index = train_full['CREATION_DATE_TIME_STAMP']\n",
                "# train_full.index = pd.DatetimeIndex(train_full.index);train_full.index\n",
                "train_full_sktime = train_full.asfreq('D')\n",
                "train_full_sktime = train_full_sktime.fillna(0);train_full_sktime\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sktime.forecasting.arima import AutoARIMA\n",
                "from sktime.forecasting.base import ForecastingHorizon\n",
                "from sktime.forecasting.theta import ThetaForecaster\n",
                "from sktime.forecasting.naive import NaiveForecaster\n",
                "from sktime.regression import ComposableTimeSeriesForestRegressor\n",
                "from sktime.forecasting.model_selection import temporal_train_test_split\n",
                "from sklearn.metrics import mean_absolute_percentage_error\n",
                "\n",
                "x = train_full_sktime.drop(['qty', 'CREATION_DATE_TIME_STAMP', 'creat_time'], axis = 1)\n",
                "y = train_full_sktime.loc[:,'qty']\n",
                "x_train, x_test , y_train, y_test = temporal_train_test_split(x, y)\n",
                "#\n",
                "#  # fh = ForecastingHorizon(x_test, is_relative=False)\n",
                "# forecaster = ComposableTimeSeriesForestRegressor(x = x_train, y = y_train)\n",
                "# forecaster.fit(x_train ,y = y_train)\n",
                "# y_pred = forecaster.predict(x_test)\n",
                "# mean_absolute_percentage_error(y_test, y_pred)\n",
                "\n",
                "forecaster = NaiveForecaster(sp = 21)\n",
                "forecaster.fit(y_train)\n",
                "\n",
                "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
                "y_pred = forecaster.predict(fh )\n",
                "mean_absolute_percentage_error(y_test, y_pred)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sktime.regression.interval_based import  TimeSeriesForestRegressor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train.shape[1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# forecaster = TimeSeriesForestRegressor( )\n",
                "# # fh = ForecastingHorizon(x_test, is_relative=False)\n",
                "# forecaster.fit(X = x_train,  y = y_train)\n",
                "# y_pred = forecaster.predict(x_test)\n",
                "# mean_absolute_percentage_error(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# prophet prepare"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train_full = train_full_sktime\n",
                "train_full = train_full.asfreq('D')\n",
                "train_full = train_full.fillna(0) \n",
                "train_first = train_first.asfreq('D')\n",
                "train_first = train_first.fillna(0)\n",
                "train_full['CREATION_DATE_TIME_STAMP'] = train_full.index\n",
                "train_first['CREATION_DATE_TIME_STAMP'] = train_first.index\n",
                "\n",
                "\n",
                "# train_full\n",
                "train_full = train_full.reset_index(drop =True)\n",
                "train_first = train_first.reset_index(drop =True)\n",
                "\n",
                "train_fin = train_full.merge(train_first, \n",
                "    on = 'CREATION_DATE_TIME_STAMP', \n",
                "    how = 'outer',\n",
                "    suffixes = ['_full', '_first'])\n",
                "train_fin = train_fin.fillna(0);train_fin"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train_full = train_full_sktime\n",
                "test_full  = test_full.asfreq('D')\n",
                "test_full  = test_full.fillna(0) \n",
                "test_first = test_first.asfreq('D')\n",
                "test_first = test_first.fillna(0)\n",
                "test_full['CREATION_DATE_TIME_STAMP']  = test_full.index\n",
                "test_first['CREATION_DATE_TIME_STAMP'] = test_first.index\n",
                "\n",
                "\n",
                "# train_full\n",
                "test_full  = test_full.reset_index(drop =True)\n",
                "test_first = test_first.reset_index(drop =True)\n",
                "\n",
                "test_fin = test_full.merge(test_first, \n",
                "    on    = 'CREATION_DATE_TIME_STAMP', \n",
                "    how   = 'outer',\n",
                "    suffixes = ['_full', '_first'])\n",
                "\n",
                "test_fin = test_fin.fillna(0);test_fin"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def span_mani(train_fin, train_first): \n",
                "    # train_full['creat_time_first'] = ''\n",
                "    train_fin['span_first'] = train_fin[\n",
                "        'creat_time_first'\n",
                "        ].str.slice(1,2).fillna(\n",
                "            0\n",
                "            ).astype(int, errors = 'ignore') + train_fin['creat_time_first'].str.slice(2,4).fillna(\n",
                "                0\n",
                "                ).astype(int, errors = 'ignore')/60*1 + 8\n",
                "\n",
                "    # # train_full['creat_time_x']\n",
                "    # train_first['span_full'] = train_first['creat_time_full'].str.slice(1,2).astype(int) + \n",
                "    #     train_first['creat_time_full'].str.slice(2,4).astype(int)/60*1 + 8\n",
                "    train_first['span_first'] = train_first[\n",
                "        'creat_time'\n",
                "        ].str.slice(1,2).fillna(\n",
                "            0\n",
                "            ).astype(int, errors = 'ignore') + train_first['creat_time'].str.slice(2,4).fillna(\n",
                "                0\n",
                "                ).astype(int, errors = 'ignore')/60*1 + 8\n",
                "    train_first = train_first.drop('creat_time', axis = 1)\n",
                "    return train_fin, train_first"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_fin, train_first = span_mani(train_fin, train_first)\n",
                "test_fin, test_first   = span_mani(test_fin, test_first) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# modeles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from sktime.forecasting.model_selection import temporal_train_test_split\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "x = train_first \n",
                "x['y'] = train_fin['qty_full']\n",
                "# x['CREATION_DATE_TIME_STAMP'] = x.index\n",
                "x_train, x_test = train_test_split(x, train_size = .75, shuffle = False, random_state = 52943)\n",
                "\n",
                "cols = [i for i in x.columns if i not in ['y', 'CREATION_DATE_TIME_STAMP']]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "\n",
                "from fbprophet import Prophet\n",
                "# df = x[['CREATION_DATE_TIME_STAMP', 'qty']]\n",
                "df_naiv = x_train \n",
                "df_naiv = df_naiv.rename({'CREATION_DATE_TIME_STAMP' : 'ds'}, axis = 1)\n",
                "m = Prophet()\n",
                "[m.add_regressor(i) for i in cols]\n",
                "\n",
                "m.fit(df_naiv)\n",
                "\n",
                "from sklearn.metrics import mean_absolute_percentage_error\n",
                "df_naiv_test = x_test\n",
                "df_naiv_test = df_naiv_test.rename({'CREATION_DATE_TIME_STAMP' : 'ds'}, axis = 1)\n",
                "# m.predict(x_test)\n",
                "mean_absolute_percentage_error(df_naiv_test['y'], m.predict(df_naiv_test)['yhat'])\n",
                "# fig = m.plot_components(m.predict(x_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# m.plot_components(m.predict(df2))\n",
                "# plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# m.plot(m.predict(df2))\n",
                "# plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " ============================== \n",
                "# pseudo labeling\n",
                " ============================== "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def labeling_mani(train_first, train_full):\n",
                "    train_first['dif'] = train_first['qty'] - train_full['qty'] != 0\n",
                "    train_first['dif'] = [1 if i == True else 0 for i in train_first['dif']]\n",
                "\n",
                "    train_full['dif'] = train_first['qty'] - train_full['qty'] != 0\n",
                "    train_full['dif'] = [1 if i == True else 0 for i in train_full['dif']]\n",
                "    return train_first , train_full\n",
                "# train_full['diff'] = train_full['qty_x'] - train_full['qty_y'] ==  0\n",
                "# train_full['diff'] = [1 if i == True else 0 for i in train_full['diff']]\n",
                "# train_full = train_full.asfreq('D')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "labeling_mani(train_first, train_full)\n",
                "test_first, test_full = labeling_mani(test_first, test_full)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = train_first.drop('y', axis  =1 )\n",
                "x_train, x_test = train_test_split(x, train_size = .75, shuffle = False, random_state = -1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "from fbprophet import Prophet \n",
                "df_lb = x_train \n",
                "\n",
                "## qty_x s是最终预测值, 所以要drop\n",
                "cols_lb = [i for i in df_lb.columns \n",
                "    if i not in ['dif', 'CREATION_DATE_TIME_STAMP']]\n",
                "\n",
                "# df_lb = df_lb.drop(['creat_time_x','creat_time_y', 'qty_x'], axis =1 )\n",
                "df_lb = df_lb.rename({'CREATION_DATE_TIME_STAMP' : 'ds', 'dif': 'y'}, axis = 1)\n",
                "m = Prophet(daily_seasonality=True) \n",
                "\n",
                "\"\"\"\n",
                "0.12379144878303337 daily_seasonality=True; empty 0.12318682390845224\n",
                "\"\"\"\n",
                "\n",
                "\n",
                "[m.add_regressor(i) for i in cols_lb]\n",
                "\n",
                "m.fit(df_lb)\n",
                "\n",
                "# ?mean_absolute_percentage_error\n",
                "from sktime.performance_metrics.forecasting import  mean_absolute_percentage_error\n",
                "from sktime.performance_metrics.forecasting import mean_absolute_error\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# x_test1 = x_test.drop(['dif'], axis =1 )\n",
                "x_test1 = x_test.rename({'CREATION_DATE_TIME_STAMP' : 'ds', 'dif': 'y'}, axis = 1)\n",
                " \n",
                "# m.predict(x_test)\n",
                "forecast = m.predict(x_test1)\n",
                "mean_absolute_error(x_test1['y'], m.predict(x_test1)['yhat'])\n",
                "# fig = m.plot_components(m.predict(x_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # %%warning = False\n",
                "# from prophet.plot import plot_plotly, plot_components_plotly\n",
                "# plot_plotly(m, forecast)\n",
                " "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lb_prophet_result = pd.DataFrame(forecast['yhat'])\n",
                "lb_prophet_result['abs_diff'] = np.abs(forecast['yhat'] - .5)\n",
                "lb_prophet_result.sort_values('abs_diff').iloc[0,0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "acc_score_data  = [1 if i>=lb_prophet_result['yhat'].mean() \\\n",
                "    else 0 for i in forecast['yhat']]\n",
                "\n",
                "acc_score_data1 = [1 if i>=lb_prophet_result.sort_values('abs_diff').iloc[0,0] \\\n",
                "    else 0 for i in forecast['yhat']]\n",
                "    \n",
                "acc_score_data2 = [1 if i>lb_prophet_result['yhat'].std() \\\n",
                "    else 0 for i in forecast['yhat']]\n",
                "\n",
                "# mean_absolute_error(x_test1['y'], m.predict(x_test1)['yhat'])\n",
                "[accuracy_score(x_test1['y'],i) for i in [acc_score_data, acc_score_data1, acc_score_data2]]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " ============================== \n",
                "## pred 2 the id number predicting:\n",
                " ============================== "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# pred 2 the id number predicting:\n",
                "id_cnt_train = train_first.copy()\n",
                "id_cnt_train = id_cnt_train[id_cnt_train['dif'] != 0]\n",
                "id_cnt_train['y'] = train_full['id']\n",
                "\"\"\"\n",
                "[4.806768544455207, 1.1680515078598923]\n",
                "[7.133413104312447, 0.6253522370101863]  # id\n",
                "\"\"\"\n",
                "# id_cnt_train['y'] = train_full['line_sum']\n",
                "\n",
                "\"\"\"\n",
                "[16.60773539220494, 0.6975939132491072] # line_sum\n",
                "\"\"\"\n",
                "id_cnt_train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# x = id_cnt_train.drop('y', axis  =1 )\n",
                "x_train, x_test = train_test_split(id_cnt_train,\\\n",
                "     train_size = .75, shuffle = False, random_state = None)\n",
                "\n",
                "## qty_x s是最终预测值, 所以要drop\n",
                "cols_lb = [i for i in x_train.columns \n",
                "    if i not in ['y', 'CREATION_DATE_TIME_STAMP']]\n",
                "\n",
                "x_train = x_train.rename({'CREATION_DATE_TIME_STAMP' : 'ds'}, axis = 1)\n",
                "m2 = Prophet(daily_seasonality=True) \n",
                "\n",
                "[m2.add_regressor(i) for i in cols_lb]\n",
                "\n",
                "m2.fit(x_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# x_test1 = x_test.drop(['dif'], axis =1 )\n",
                "x_test1 = x_test.rename({'CREATION_DATE_TIME_STAMP' : 'ds'}, axis = 1)\n",
                " \n",
                "# m.predict(x_test)\n",
                "forecast_2 = m2.predict(x_test1)\n",
                "[mean_absolute_error(x_test1['y'], forecast_2['yhat']),\\\n",
                "     mean_absolute_percentage_error(x_test1['y'], forecast_2['yhat'])]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " ============================== \n",
                "# test data validate \n",
                " \n",
                " \n",
                " ============================== \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_all = x\n",
                "train_all = train_all.rename({'CREATION_DATE_TIME_STAMP' : 'ds', 'dif': 'y'}, axis = 1)\n",
                "# m2 = Prophet(daily_seasonality=True) \n",
                "# m2.fit(train_all)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# a\n",
                "test_all  = test_first.rename({'CREATION_DATE_TIME_STAMP' : 'ds', 'dif': 'y'}, axis = 1)\n",
                "test_pred = m.predict(test_all)\n",
                " \n",
                "mean_absolute_error(test_all['y'], test_pred['yhat'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "acc_tst = [1 if i>=test_pred['yhat'].mean() \\\n",
                "    else 0 for i in test_pred['yhat']]\n",
                "accuracy_score(acc_tst, test_all['y'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nbformat\n",
                "nbformat.__version__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import plotly.express as px"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# %%warning = False\n",
                "test_pre_p = go.Figure()\n",
                "test_pre_p.add_trace(go.Scatter(x = test_pred['ds'],\\\n",
                "    y = test_pred['yhat'], \n",
                "    mode = 'markers',\n",
                "    name = 'pred'))\n",
                "test_pre_p.add_trace(go.Scatter(x = test_all['ds'], \\\n",
                "    y = test_all['y'], \n",
                "    mode = 'markers',\n",
                "    name = 'original_out'))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # %%warning = False\n",
                "# test_pre_p = go.Figure()\n",
                "# test_pre_p.add_trace(go.Scatter(x = test_all['ds'], \\\n",
                "#     y = test_all['y'], \n",
                "#     mode = 'markers',\n",
                "#     name = 'original_out'))\n",
                "# test_pre_p.add_trace(go.Scatter(x = test_pred['ds'],\\\n",
                "#     y = test_pred['yhat'], \n",
                "#     mode = 'markers',\n",
                "#     name = 'pred'))\n",
                "# test_pre_p.show() "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "----\n",
                "## try h2o predict qty"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train2 = x_train[x_train['dif'] == 1] \n",
                "x_test2 = x_test[x_test['dif'] == 1];len(x_test2)\n",
                "x_train2['qty_tar'] = train_full[train_full['dif'] == 1].iloc[0:len(x_train2), :]['qty']\n",
                "x_test2['qty_tar'] = train_full[train_full['dif'] == 1].iloc[len(x_train2):, :]['qty'];x_train2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import h2o\n",
                "from h2o.estimators import H2OIsolationForestEstimator\n",
                "from h2o.estimators import H2ODeepLearningEstimator\n",
                "from h2o.estimators import H2OXGBoostEstimator\n",
                "h2o.init()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_h2o = [i for i in x_train2.columns.to_numpy() if i not in 'qty_tar']\n",
                "\n",
                "# Import the prostate dataset\n",
                "h2o_df = h2o.H2OFrame(x_train2)\n",
                "# Split the data giving the training dataset 75% of the data\n",
                "train,test = h2o_df.split_frame(ratios=[0.75])\n",
                "\n",
                "# Build an Isolation forest model\n",
                "model = H2OIsolationForestEstimator(sample_rate = 0.1,\n",
                "                                    max_depth = 20,\n",
                "                                    ntrees = 500)\n",
                "model.train(training_frame=train,x =cols_h2o)\n",
                "\n",
                "# Calculate score\n",
                "score = model.predict(test)\n",
                "result_pred = score[\"predict\"]\n",
                "\n",
                "# Predict the leaf node assignment\n",
                "ln_pred = model.predict_leaf_node_assignment(test, \"Path\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "score_train = model.predict(train)\n",
                "forest_pred_trai = pd.concat([score_train['predict'].as_data_frame(),\\\n",
                "    result_pred.as_data_frame() ], axis = 0).reset_index()\n",
                "forest_pred_test = model.predict(h2o.H2OFrame(x_test2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train.as_data_frame()\n",
                "train.as_data_frame().append(score_train.as_data_frame())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "score2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions on a test set (if necessary):\n",
                "pred = dl.predict(test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sult = pd.concat([test.as_data_frame()['qty_tar'], pred.as_data_frame()], axis = 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sult"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mean_absolute_percentage_error(sult['qty_tar'], sult['predict'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train2 = x_train2.reset_index()\n",
                "x_test2 = x_test2.reset_index()\n",
                "x_train2['labels'] = forest_pred_trai['predict'] \n",
                "x_test2['labels'] = forest_pred_test.as_data_frame()['predict']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictors = [i for i in x_train2.columns.to_numpy() if i not in 'qty_tar']\n",
                "response = 'qty_tar'\n",
                "# Import the prostate dataset\n",
                "h2o_df = h2o.H2OFrame(x_train2)\n",
                "# Split the data giving the training dataset 75% of the data\n",
                "train,test = h2o_df.split_frame(ratios=[0.75])\n",
                "\n",
                "dl = H2ODeepLearningEstimator(distribution=\"AUTO\",\n",
                "                               hidden=[300,300],\n",
                "                               epochs=600,\n",
                "                               train_samples_per_iteration=-1,\n",
                "                               reproducible=True,\n",
                "                               activation=\"Rectifierwithdropout\",\n",
                "                               single_node_mode=False,\n",
                "                               balance_classes=False,\n",
                "                               force_load_balance=False,\n",
                "                               seed=707,\n",
                "                               tweedie_power=1.5,\n",
                "                               score_training_samples=0,\n",
                "                               score_validation_samples=0,\n",
                "                               score_each_iteration = True,\n",
                "                               stopping_rounds=0)\n",
                "dl.train(x=predictors,\n",
                "         y=response,\n",
                "          training_frame= train,\n",
                "          validation_frame = test)\n",
                "\n",
                "# Eval performance:\n",
                "perf = dl.model_performance();perf\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "perf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_lb_qty_test2 = dl.predict(test).as_data_frame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_lb_qty_test2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mean_absolute_percentage_error(sult['qty_tar'], sult['predict'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "----\n",
                "## Darts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_lb , x_test1 \n",
                "\n",
                "\"\"\"\n",
                "the dataframes are taken from fbprophet model, \n",
                "no need to split anyway.\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from darts import TimeSeries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from darts import TimeSeries\n",
                "\n",
                "series_train = TimeSeries.from_dataframe(df_lb, \n",
                "       time_col = 'ds', \n",
                "       value_cols ='y')\n",
                "series_test = TimeSeries.from_dataframe(x_test1, \n",
                "       time_col = 'ds', \n",
                "       value_cols =  'y')\n",
                "series_train_cov = TimeSeries.from_dataframe(df_lb,\\\n",
                "       'ds',\n",
                "       ['id', 'line_sum', 'container_sum', 'weight', 'qty', 'span_first'])\n",
                "series_test_cov = TimeSeries.from_dataframe(x_test1, \n",
                "       'ds', \n",
                "       ['id', 'line_sum', 'container_sum', 'weight', 'qty', 'span_first'] )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ful_span = TimeSeries.from_dataframe(df_lb.append(x_test1), \\\n",
                "    'ds', \n",
                "    value_cols = 'y')\n",
                "ful_span_cov = TimeSeries.from_dataframe(df_lb.append(x_test1), \\\n",
                "    'ds', \n",
                "    ['id', 'line_sum', 'container_sum', 'weight', 'qty', 'span_first'] )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from darts.models import RNNModel\n",
                "md1_bert = NBEATSModel(input_chunk_length=31, \\\n",
                "    output_chunk_length=15, n_epochs=5, random_state=43)\n",
                "    \n",
                "# md2_lstm = BlockRNNModel(model='LSTM', \\\n",
                "#     input_chunk_length=12, output_chunk_length=6, n_epochs=5, random_state=43)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " > ## *Past Covariates denote time series whose past values are known at prediction time. These are usually things that have to be measured or observed. * Future Covariates denote time series whose future values are already known at prediction time for the span of the forecast horizon. These can for instance represent known future holidays, or weather forecasts.*\n",
                "> \n",
                "> \n",
                " > ## input_chunk_length: this is the length of the lookback window of the model; so each output will be computed by the model by reading the previous input_chunk_length points. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "md1_bert.fit(series = series_train, \\\n",
                "    past_covariates = series_train_cov,\n",
                "    verbose=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "backtest_bert = md1_bert.historical_forecasts(series_train,\\\n",
                "    past_covariates = series_train_cov,\n",
                "    start = .75,\n",
                "    retrain = False)\n",
                "\n",
                "# backtest_cov = model_cov.historical_forecasts(series_air_scaled,\n",
                "#                                               past_covariates=air_covariates,\n",
                "#                                               start=0.6,\n",
                "#                                               forecast_horizon=12,\n",
                "#                                               stride=1,\n",
                "#                                               retrain=False,\n",
                "#                                               verbose=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "backtest_bert.values()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "train_pred_bert = md1_bert.predict(n = 334 , \n",
                "    past_covariates = series_train_cov,\n",
                "    # future_covariates = series_test_cov\n",
                "    )\n",
                "train_pred_bert.values()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from darts.metrics import mape\n",
                "mean_absolute_error(train_pred_bert.values(), series_test.values())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## lSTM in darts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "LSTM_darts = RNNModel(\n",
                "    model='LSTM',\n",
                "    hidden_dim=20,\n",
                "    dropout=0,\n",
                "    batch_size=7,\n",
                "    n_epochs=5,\n",
                "    optimizer_kwargs={'lr': 1e-3},\n",
                "    model_name='lstm_RNN',\n",
                "    log_tensorboard=True,\n",
                "    random_state=42,\n",
                "    # training_length=20,\n",
                "    input_chunk_length=31,\n",
                "    force_reset=True\n",
                ")\n",
                "LSTM_darts.fit(series_train,\n",
                "             future_covariates=series_train_cov,\n",
                "            #  val_series=series_test,\n",
                "            #  val_future_covariates=series_test_cov,\n",
                "             verbose=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.set_printoptions(suppress=True)\n",
                "lstm_pred_test = LSTM_darts.predict(n = 334, future_covariates = ful_span_cov).values()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "acc_score_data  = [1 if i>=lstm_pred_test.mean() \\\n",
                "    else 0 for i in lstm_pred_test]\n",
                "\n",
                "# acc_score_data1 = [1 if i>=lstm_pred_test.sort_values() \\\n",
                "#     else 0 for i in forecast['yhat']]\n",
                "    \n",
                "# acc_score_data2 = [1 if i>lb_prophet_result['yhat'].std() \\\n",
                "#     else 0 for i in forecast['yhat']]\n",
                "\n",
                "# mean_absolute_error(x_test1['y'], m.predict(x_test1)['yhat'])\n",
                "# [accuracy_score(x_test1['y'],i) for i in [acc_score_data, acc_score_data1, acc_score_data2]]\n",
                "accuracy_score(x_test1['y'],acc_score_data) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lstm_plt = x_test1.copy()\n",
                "lstm_plt['y_pred'] = lstm_pred_test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import plotly.express as ex\n",
                "fig = ex.scatter(data_frame=lstm_plt, x = 'ds', y = 'y')\n",
                "fig.add_scatter(x = lstm_plt['ds'],  y = lstm_plt['y_pred'])\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import altair as alt\n",
                "# brush = alt.selection_interval()\n",
                "# alt.Chart(lstm_plt).mark_point().encode(\n",
                "#     x='ds',\n",
                "#     y='y'\n",
                "# ).add_selection(\n",
                "#     brush\n",
                "# )\n",
                " "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# min(abs(lstm_plt['y_pred'] - .5))\n",
                "\n",
                "lstm_plt['abs_diff'] = np.abs(lstm_plt['y_pred'] - .5)\n",
                "lstm_plt.sort_values('abs_diff')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pred_1_lable1 = [1 if i> 0.565032 else 0 for i in lstm_plt['y_pred']]\n",
                "# lstm_plt['y_pred']\n",
                "pred_1_lable2 = [1 if i> lstm_plt['y_pred'].mean() else 0 for i in lstm_plt['y_pred']]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import mean_absolute_percentage_error\n",
                "[accuracy_score(lstm_plt['y'], pred_1_lable1),\n",
                "accuracy_score(lstm_plt['y'], pred_1_lable2)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "# series.plot(label='data')\n",
                "# for i, m in enumerate(berkets):\n",
                "#     err = mape(backtests[i], series)\n",
                "#     backtests[i].plot(lw=3, label='{}, MAPE={:.2f}%'.format(m, err))\n",
                "\n",
                "# plt.title('Backtests with 3-months forecast horizon')\n",
                "# plt.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## qty prediction, filter data which not 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train2 = x_train[x_train['dif'] == 1] \n",
                "x_test2 = x_test[x_test['dif'] == 1];len(x_test2)\n",
                "x_train2['qty_tar'] = train_full[train_full['dif'] == 1].iloc[0:len(x_train2), :]['qty']\n",
                "x_test2['qty_tar'] = train_full[train_full['dif'] == 1].iloc[len(x_train2):, :]['qty']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[len(x_train2),len(x_test2)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_2_all = pd.DataFrame(pd.concat([x_train2, x_test2], axis = 0)).reset_index(); df_2_all"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "tran3 = ColumnTransformer([\n",
                "        ('somename', StandardScaler(), ['weight', 'qty', 'qty_tar'])\n",
                "    ])\n",
                "tran3.fit(df_2_all[['weight', 'qty', 'qty_tar']])\n",
                "\n",
                "df_2_all[['weight', 'qty',  'qty_tar']] = pd.DataFrame(\n",
                "    tran3.fit_transform(df_2_all[['weight', 'qty', 'qty_tar']])\n",
                "\n",
                ") "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# tran2.fit(x_train2[['weight', 'qty', 'span_first']])\n",
                "# tran2.transform(x_test2[['weight', 'qty', 'span_first']])\n",
                "\n",
                "df_2_all =df_2_all.fillna(0)\n",
                "x_train2 = df_2_all.iloc[0:652,:]\n",
                "x_test2 = df_2_all.iloc[652:,:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fbprophet import Prophet \n",
                "df_lb = x_train2\n",
                "\n",
                "## qty_x s是最终预测值, 所以要drop\n",
                "cols_lb = [i for i in df_lb.columns \n",
                "    if i not in ['qty_tar', 'CREATION_DATE_TIME_STAMP']]\n",
                "\n",
                "# df_lb = df_lb.drop(['creat_time_x','creat_time_y', 'qty_x'], axis =1 )\n",
                "df_lb = df_lb.rename({'CREATION_DATE_TIME_STAMP' : 'ds', 'qty_tar': 'y'}, axis = 1)\n",
                "m = Prophet(daily_seasonality=True)\n",
                "[m.add_regressor(i) for i in cols_lb]\n",
                "\n",
                "m.fit(df_lb)\n",
                "\n",
                "\n",
                "# ?mean_absolute_percentage_error\n",
                "from sktime.performance_metrics.forecasting import  mean_absolute_percentage_error\n",
                "from sktime.performance_metrics.forecasting import mean_absolute_error\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# x_test1 = x_test.drop(['dif'], axis =1 )\n",
                "x_test1 = x_test2.rename({'CREATION_DATE_TIME_STAMP' : 'ds', 'qty_tar': 'y'}, axis = 1)\n",
                " \n",
                "# m.predict(x_test)\n",
                "forecast = m.predict(x_test1)\n",
                "mean_absolute_percentage_error(x_test1['y'], m.predict(x_test1)['yhat'])\n",
                "# fig = m.plot_components(m.predict(x_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# cross validation on prophet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from prophet.diagnostics import cross_validation, performance_metrics\n",
                "df_cv = cross_validation(m, initial='365 days', period='31 days', horizon = '180 days')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_cv = pd.DataFrame(df_cv);df_cv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.scatterplot(data = df_cv, x = 'ds', y = 'yhat')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "performance_metrics(df_cv).sort_values('mae')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tunning paras"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fbprophet import Prophet \n",
                "df_lb = x_train \n",
                "cols_lb = [i for i in df_lb.columns \n",
                "    if i not in ['diff','qty_x','creat_time_x','creat_time_y','CREATION_DATE_TIME_STAMP']]\n",
                "\n",
                "df_lb = df_lb.drop(['creat_time_x','creat_time_y', 'qty_x'], axis =1 )\n",
                "df_lb = df_lb.rename({'CREATION_DATE_TIME_STAMP' : 'ds', 'diff': 'y'}, axis = 1)\n",
                "m = Prophet()\n",
                "[m.add_regressor(i) for i in cols_lb]\n",
                "\n",
                "m.fit(df_lb)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%Time\n",
                "import itertools\n",
                "param_grid = {  \n",
                "    'changepoint_prior_scale': [0.01,  0.5],\n",
                "    'seasonality_prior_scale': [0.01, 0.1],\n",
                "}\n",
                " \n",
                "\n",
                "# Generate all combinations of parameters\n",
                "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
                "rmses = []  # Store the RMSEs for each params here\n",
                "\n",
                "# Use cross validation to evaluate all parameters\n",
                "for params in all_params:\n",
                "    m = Prophet(**params)  # Fit model with given params\n",
                "    [m.add_regressor(i) for i in cols_lb]\n",
                "    m.fit(df_lb)\n",
                "    df_cv = cross_validation(m, \n",
                "        initial='365 days', period='31 days', horizon = '180 days', parallel=\"processes\")\n",
                "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
                "    rmses.append(df_p['rmse'].values[0])\n",
                "\n",
                "# Find the best parameters\n",
                "tuning_results = pd.DataFrame(all_params)\n",
                "tuning_results['rmse'] = rmses\n",
                "print(tuning_results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Python\n",
                "best_params = all_params[np.argmin(rmses)]\n",
                "print(best_params)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_lb"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_test1 = x_test.drop(['creat_time_x','creat_time_y', 'qty_x', 'diff'], axis =1 )\n",
                "x_test1 = x_test1.rename({'CREATION_DATE_TIME_STAMP' : 'ds'}, axis = 1)\n",
                "x_test1['y'] = 0\n",
                "m.predict(x_test1)\n",
                "mean_absolute_error(x_test['diff'], m.predict(x_test1)['yhat'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "values = m.predict(x_test1)['yhat']\n",
                "labels = [1 if i>.5 else 0 for i in values]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_test['pred_labels'] = labels;x_test\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "accuracy_score(x_test['diff'], x_test['pred_labels'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# qty_x is target\n",
                "from fbprophet import Prophet \n",
                "df_value = x_train \n",
                "df_value = df_value.drop(['creat_time_x','creat_time_y'], axis =1 )\n",
                "\n",
                "df_value = df_value.rename({\n",
                "    'CREATION_DATE_TIME_STAMP' : 'ds', 'qty_x': 'y', 'diff':'pred_labels'\n",
                "    }, axis = 1)\n",
                "\n",
                "    \n",
                "cols_value = [i for i in df_value.columns \n",
                "    if i not in ['y', 'ds', 'pred_labels']]\n",
                "\n",
                "m = Prophet()\n",
                "[m.add_regressor(i) for i in cols_value]\n",
                "\n",
                "m.fit(df_value)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_value"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_test_fin = x_test.drop(['creat_time_x','creat_time_y', 'qty_x', 'diff'], axis =1 )\n",
                " \n",
                "x_test_fin = x_test_fin.rename({'CREATION_DATE_TIME_STAMP' : 'ds'}, axis = 1);\n",
                "x_test_fin"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# m.predict(x_test_fin)\n",
                "mean_absolute_percentage_error(x_test['qty_x'], m.predict(x_test_fin)['yhat'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# aaa"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
                "from sklearn import model_selection\n",
                "cv_split = model_selection.ShuffleSplit(\n",
                "    n_splits = 6, \n",
                "    test_size = .25, \n",
                "    # max_train_size = .75\n",
                "    )\n",
                "alg1 = Lasso()\n",
                "\n",
                "cv_results_1 = model_selection.cross_validate(\n",
                "    alg1, \n",
                "    train_first.drop(['qty2','CREATION_DATE_TIME_STAMP','creat_time'], axis =1) , train_first['qty2'].to_numpy(), \n",
                "    cv  = cv_split, scoring='neg_mean_absolute_percentage_error')\n",
                "\n",
                "\n",
                "cv_results_1['test_score'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestRegressor\n",
                "alg2 = RandomForestRegressor(n_estimators = 34, \n",
                "        max_depth = 61,\n",
                "        min_samples_split = 3, \n",
                "        min_samples_leaf=4, \n",
                "        # max_leaf_nodes = 31\n",
                "        )\n",
                "cv_results_2 = model_selection.cross_validate(\n",
                "        alg2, \n",
                "        train_first, \n",
                "        train_full['qty'], \n",
                "        cv  = cv_split, scoring='neg_mean_absolute_percentage_error')\n",
                "cv_results_2['test_score'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "alg2.fit(train_first,train_full['qty']).predict(train_first)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.neural_network import MLPRegressor\n",
                "alg3 = MLPRegressor(\n",
                "    hidden_layer_sizes = (891, 891, 450, 135), \n",
                "    max_iter=1000,\n",
                "    verbose=True, \n",
                "    activation = 'identity', \n",
                "    solver = 'adam', learning_rate = 'adaptive')\n",
                "cv_results_3 = model_selection.cross_validate(\n",
                "    alg3, train_first,train_full['qty'], \n",
                "    cv  = cv_split, \n",
                "    scoring='neg_mean_absolute_percentage_error')\n",
                "cv_results_3['test_score'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.neural_network import MLPRegressor\n",
                "alg3 = MLPRegressor(\n",
                "    hidden_layer_sizes = (1120, 850, 450, 135), \n",
                "    max_iter=1000,\n",
                "    verbose=True, \n",
                "    activation = 'relu', \n",
                "    solver = 'adam', \n",
                "    learning_rate = 'adaptive',\n",
                "    warm_start = True,\n",
                "    early_stopping = True\n",
                "    )\n",
                "cv_results_3 = model_selection.cross_validate(\n",
                "    alg3, train_first,train_full['qty'], \n",
                "    cv  = cv_split, \n",
                "    scoring='neg_mean_absolute_percentage_error')\n",
                "cv_results_3['test_score'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "47b50d2908d96196e4220cfb4e81faa93803065ea975497e7026f672c1f58470"
        },
        "kernelspec": {
            "display_name": "Python 3.8.8 64-bit ('siming': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.8"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
