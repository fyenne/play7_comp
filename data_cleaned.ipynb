{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OD集货量',\n",
       " '中转场历史到件量0301至0531.csv',\n",
       " '中转场历史到件量0601至0831.csv',\n",
       " '场地数据.csv',\n",
       " '班次数据0601至0831.csv',\n",
       " '运力配载数据0601至0831']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "path = './' + 'data/'\n",
    "os.listdir(path)\n",
    "# os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# trans = pd.read_json('./data/运力配载数据0601至0831/line_info_0601.json', lines=True)  # 36.2 sec\n",
    "hist_arr = pd.read_csv(path + '中转场历史到件量0601至0831.csv')\n",
    "loc = pd.read_csv(path + '场地数据.csv')\n",
    "# # # loc.to_csv(path + '场地数据.csv', index = None, encoding='utf_8_sig')\n",
    "task_arrange = pd.read_csv(path + '班次数据0601至0831.csv')\n",
    "\n",
    "\n",
    "path_od = path + 'OD集货量/sep/'   \n",
    "dfs = pd.DataFrame()\n",
    "for fname in os.listdir(path_od):\n",
    "    if re.search(r'\\.csv$', fname):\n",
    "        dfs = pd.concat(\n",
    "            [dfs , pd.read_csv(path_od + fname)], axis = 0, ignore_index = True)\n",
    "prc_in = pd.DataFrame(dfs) \n",
    "print(\n",
    "    'loc:', loc.shape, '\\nhist:' ,\n",
    "    hist_arr.shape, '\\ntask:',\n",
    "    task_arrange.shape, '\\nod:' ,\n",
    "    dfs.shape)\n",
    "del dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the story\n",
    "以od为主表 通过时间和destination location join **history** 和 task ; location, 对task 和location中的缺失值进行处理.\n",
    "location和task中的部分特征进行处理.\n",
    "未来计划加入路线数据."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Loc table clean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = pd.read_pickle('./data_clean/loc.p'); loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "loc[loc['场地代码'] == '552W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc.columns\n",
    "def loc_(loc):\n",
    "    loc = loc.drop(['所在城市代码','应用场景', '分拨区' , '所在城市名称', '场地名称', '主服务城市','所在区部'], axis = 1) \n",
    "    loc[[ '卸车卡位（17.5M）', '卸车卡位（>=15M）', '卸车卡位（<15M）', '装车卡位（17.5M）', '装车卡位（15M）',\n",
    "        '装车卡位（13.5M）', '装车卡位（9.6M）', '装车卡位（7.6M）', '装车卡位（5.2M）']]  = loc[[ '卸车卡位（17.5M）', '卸车卡位（>=15M）', '卸车卡位（<15M）', '装车卡位（17.5M）', '装车卡位（15M）',\n",
    "        '装车卡位（13.5M）', '装车卡位（9.6M）', '装车卡位（7.6M）', '装车卡位（5.2M）']] == 0\n",
    "    # loc[['装车卡位（13.5M）', '装车卡位（9.6M）', '装车卡位（7.6M）', '装车卡位（5.2M）']].describe()\n",
    "    # loc.head(2)\n",
    "    loc['off_1'] = loc['卸车卡位（17.5M）'] * 17.5\n",
    "    loc['off_2'] = loc['卸车卡位（>=15M）'] * 15\n",
    "    loc['off_3'] = loc['卸车卡位（<15M）'] * (13.5 * 0.970721 + 9.6 * 11.056306 + 7.6 * 2.279279 + 5.2 * 9.826577)/ \\\n",
    "        (0.970721 + 11.056306 + 2.279279 + 9.826577)\n",
    "    loc['onn_1'] = loc['装车卡位（17.5M）'] * 17.5\n",
    "    loc['onn_2'] = loc['装车卡位（15M）'] * 15\n",
    "    loc['onn_3'] = loc['装车卡位（13.5M）'] * 13.5\n",
    "    loc['onn_4'] = loc['装车卡位（9.6M）'] * 9.6\n",
    "    loc['onn_5'] = loc['装车卡位（7.6M）'] * 7.6\n",
    "    loc['onn_6'] = loc['装车卡位（5.2M）'] * 5.2\n",
    "    loc['off'] = loc['off_1'] + loc['off_2'] + loc['off_3']\n",
    "    loc['onn'] = loc['onn_1'] + loc['onn_2'] + loc['onn_3'] + loc['onn_4'] + loc['onn_5'] + loc['onn_6']\n",
    "    loc = loc.drop(['off_1','off_2', 'off_3', 'onn_1', 'onn_2', 'onn_3', 'onn_4', 'onn_5', 'onn_6'], axis = 1)\n",
    "\n",
    "    loc['off_p1'] = loc['off']/(loc['卸货卡位总数']+1)\n",
    "    loc['off_p2'] = loc['off']/(loc['装货卡位总数']+1)\n",
    "    loc['onn_p1'] = loc['onn']/(loc['卸货卡位总数']+1)\n",
    "    loc['onn_p2'] = loc['onn']/(loc['装货卡位总数']+1)\n",
    "    return loc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc.to_pickle('./data_clean/loc.p')\n",
    "# corr_loc = loc.corr()\n",
    "# corr_loc.style.background_gradient(cmap='coolwarm', axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task arrage clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_arrange[(task_arrange['operate_zone_code'] == '552W') & (task_arrange['batch_date'] == '2021-06-04')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(ta,  './data_clean/task.p')\n",
    "ta = pd.read_pickle('./data_clean/task.p')\n",
    "# task_loc[task_loc['operate_zone_code'] == '010R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def ta_(ta):\n",
    "    ta = ta.groupby(['operate_zone_code', 'batch_date']).\\\n",
    "        agg(min_begin = ('plan_begin_tm', min),\n",
    "        max_begin = ('plan_begin_tm', max),\n",
    "        min_end = ('plan_end_tm', min),\n",
    "        max_end = ('plan_end_tm', max),\n",
    "        count = ('batch_code', 'nunique')\n",
    "        \n",
    "        ).reset_index()\n",
    "\n",
    "    def convt_min(col):\n",
    "        ta[col] = ta[col].apply(lambda i: datetime.strptime(i,'%H:%M').hour*60 + datetime.strptime(i,'%H:%M').minute)\n",
    "        \n",
    "    for i in ['min_begin', 'max_begin', 'min_end','max_end']:\n",
    "        convt_min(i)\n",
    "    return ta\n",
    "\n",
    "\n",
    "# ta['time_consume_per_vote'] = (ta['max_end'] - ta['min_begin'])/ta['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_ta = ta.corr()\n",
    "corr_ta.style.background_gradient(cmap='coolwarm', axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import matplotlib.pyplot as plt\n",
    "# ta_plt2 = pd.DataFrame(ta['operate_zone_code'].value_counts())\n",
    "# ta_plt2 = pd.DataFrame(ta_plt2['operate_zone_code'].value_counts())\n",
    "# ta_plt2['site'] = ta_plt2.index\n",
    "# plt.pie(x = 'operate_zone_code' , data =ta_plt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# task_loc = ta.merge(loc, left_on='operate_zone_code', right_on = '场地代码', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "del loc, ta \n",
    "# task_loc.to_pickle('./data_clean/task_loc.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# task_loc_valued = task_loc[~task_loc['场地代码'].isna()]\n",
    "# task_loc_nulled = task_loc[task_loc['场地代码'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_loc.isnull().sum()/len(task_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n历史到件量的场地不是每个都需要考虑的吧 集货OD对应的场地应该只有400出头 场地数据基本能覆盖的\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od_dest = pd.read_pickle('./data_clean/od_dest.p') \n",
    "\"\"\"\n",
    "历史到件量的场地不是每个都需要考虑的吧 集货OD对应的场地应该只有400出头 场地数据基本能覆盖的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[prc_in[(prc_in['date1'] == '2021-06-08') & (prc_in['destsitecode'] == '552W')].sum(),\n",
    "prc_in[(prc_in['date1'] == '2021-06-04') & (prc_in['srcsitecode'] == '552W')].sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prc_in.head()\n",
    "def od_(od):\n",
    "    od = od.groupby(['srcsitecode','destsitecode', 'date1']).agg(\n",
    "        batch_cnt = ('srcbatchcode', 'nunique'),\n",
    "        route_cnt = ('route_code', 'nunique'),\n",
    "        votes = ('votes', sum),\n",
    "        weights = ('weight1', sum),\n",
    "        air_votes =('air_votes', sum),\n",
    "        air_weights = ('air_weight1', sum)\n",
    "    ).reset_index()\n",
    "\n",
    "    od_dest = od.groupby(['destsitecode', 'date1']).agg(\n",
    "        {'batch_cnt': sum, \n",
    "        'route_cnt': sum,\n",
    "        'votes': sum, \n",
    "        'weights': sum,\n",
    "        'air_votes': sum, \n",
    "        'air_weights':sum\n",
    "        }).reset_index();od_dest\n",
    "    return od_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od.to_pickle('./data_clean/od.p')\n",
    "# od_dest.to_pickle('./data_clean/od_dest.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[od.date1.unique(), od.date1.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_arr[(hist_arr['a.zonecode'] == '552W') & ( hist_arr['a.report_dt'] == '2021-06-04' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a.report_dt</th>\n",
       "      <th>a.zonecode</th>\n",
       "      <th>all_arr_waybill</th>\n",
       "      <th>all_arr_weight</th>\n",
       "      <th>simu_arr_waybill</th>\n",
       "      <th>simu_arr_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>010CC006</td>\n",
       "      <td>525</td>\n",
       "      <td>1280.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>010CC007</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>010R</td>\n",
       "      <td>102944</td>\n",
       "      <td>230415.243664</td>\n",
       "      <td>76818</td>\n",
       "      <td>165515.803556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>010RA</td>\n",
       "      <td>109154</td>\n",
       "      <td>249089.557278</td>\n",
       "      <td>109154</td>\n",
       "      <td>249089.557278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>010RG</td>\n",
       "      <td>119183</td>\n",
       "      <td>261849.663955</td>\n",
       "      <td>118678</td>\n",
       "      <td>260439.168955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  a.report_dt a.zonecode  all_arr_waybill  all_arr_weight  simu_arr_waybill  \\\n",
       "0  2021-06-08   010CC006              525     1280.400000                 0   \n",
       "1  2021-06-08   010CC007                0        0.000000                 0   \n",
       "2  2021-06-08       010R           102944   230415.243664             76818   \n",
       "3  2021-06-08      010RA           109154   249089.557278            109154   \n",
       "4  2021-06-08      010RG           119183   261849.663955            118678   \n",
       "\n",
       "   simu_arr_weight  \n",
       "0         0.000000  \n",
       "1         0.000000  \n",
       "2    165515.803556  \n",
       "3    249089.557278  \n",
       "4    260439.168955  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hist_arr.to_pickle('./data_clean/hist_arr.p')\n",
    "# merge all\n",
    "hist_arr = pd.read_pickle('./data_clean/hist_arr.p')\n",
    "hist_arr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data subset to 10 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_arr_part = hist_arr[hist_arr['a.report_dt'] < '2021-06-11']\n",
    "\n",
    "# od_dest = od.groupby(['destsitecode', 'date1']).agg(\n",
    "#     {'batch_cnt': sum, \n",
    "#     'route_cnt': sum,\n",
    "#     'votes': sum, \n",
    "#     'weights': sum,\n",
    "#     'air_votes': sum, \n",
    "#     'air_weights':sum\n",
    "#     }).reset_index();od_dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# merge od_dest, ta, loc, hist_arr_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Index(['operate_zone_code', 'batch_date', 'min_begin', 'max_begin', 'min_end',\n",
       "        'max_end', 'count'],\n",
       "       dtype='object'),\n",
       " Index(['destsitecode', 'date1', 'batch_cnt', 'route_cnt', 'votes', 'weights',\n",
       "        'air_votes', 'air_weights'],\n",
       "       dtype='object'),\n",
       " Index(['场地代码', '场地类型', '主服务业务区', '单小时处理能力', '卸货卡位总数', '卸车卡位（17.5M）',\n",
       "        '卸车卡位（>=15M）', '卸车卡位（<15M）', '装货卡位总数', '装车卡位（17.5M）', '装车卡位（15M）',\n",
       "        '装车卡位（13.5M）', '装车卡位（9.6M）', '装车卡位（7.6M）', '装车卡位（5.2M）', 'off', 'onn',\n",
       "        'off_p1', 'off_p2', 'onn_p1', 'onn_p2'],\n",
       "       dtype='object'),\n",
       " Index(['a.report_dt', 'a.zonecode', 'all_arr_waybill', 'all_arr_weight',\n",
       "        'simu_arr_waybill', 'simu_arr_weight'],\n",
       "       dtype='object')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ta.columns,\n",
    "od_dest.columns,\n",
    "loc.columns,\n",
    "hist_arr.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1126 测试集 限制场地为test set 当中的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['od_data_day1_day5.csv',\n",
       " 'od_data_day6_day10.csv',\n",
       " 'OD集货量.7z.001',\n",
       " '中转场历史到件量day_1至day_6.csv',\n",
       " '场地数据.xlsx',\n",
       " '班次day_1至day_10.csv',\n",
       " '结果输出格式&待预测场地列表.xlsx']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# os.listdir('testset')\n",
    "test_out = pd.read_excel('./testset/结果输出格式&待预测场地列表.xlsx')\n",
    "hist_test = pd.read_csv('./testset/中转场历史到件量day_1至day_6.csv')\n",
    "loc_test = pd.read_excel('./testset/场地数据.xlsx')\n",
    "od_test1 = pd.read_csv('./testset/od_data_day1_day5.csv')\n",
    "od_test2 = pd.read_csv('./testset/od_data_day6_day10.csv')\n",
    "ta_test =  pd.read_csv('./testset/班次day_1至day_10.csv')\n",
    "# hist_test =  pd.read_csv('./testset/中转场历史到件量day_1至day_6.csv')\n",
    "od_test = pd.concat([od_test1, od_test2], axis = 0)\n",
    "# os.listdir('testset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ta_test = ta_(ta_test)\n",
    "loc_test = loc_(loc_test)\n",
    "loc_all = pd.concat([loc_test, loc], axis = 0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "od_test = od_(od_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destsitecode</th>\n",
       "      <th>date1</th>\n",
       "      <th>batch_cnt</th>\n",
       "      <th>route_cnt</th>\n",
       "      <th>votes</th>\n",
       "      <th>weights</th>\n",
       "      <th>air_votes</th>\n",
       "      <th>air_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010R</td>\n",
       "      <td>day_10_weekday_7</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>49.0</td>\n",
       "      <td>138.470000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>277.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010R</td>\n",
       "      <td>day_1_weekday_5</td>\n",
       "      <td>137</td>\n",
       "      <td>110</td>\n",
       "      <td>22.0</td>\n",
       "      <td>228.006667</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>6778.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010R</td>\n",
       "      <td>day_2_weekday_6</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.330000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010R</td>\n",
       "      <td>day_3_weekday_7</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.150000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>223.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010R</td>\n",
       "      <td>day_4_weekday_1</td>\n",
       "      <td>168</td>\n",
       "      <td>145</td>\n",
       "      <td>66.0</td>\n",
       "      <td>174.100000</td>\n",
       "      <td>4093.0</td>\n",
       "      <td>7151.521364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>SIN01R</td>\n",
       "      <td>day_5_weekday_2</td>\n",
       "      <td>250</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>860.0</td>\n",
       "      <td>3797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>SIN01R</td>\n",
       "      <td>day_6_weekday_3</td>\n",
       "      <td>252</td>\n",
       "      <td>148</td>\n",
       "      <td>11.0</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>885.0</td>\n",
       "      <td>4001.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>SIN01R</td>\n",
       "      <td>day_7_weekday_4</td>\n",
       "      <td>269</td>\n",
       "      <td>169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>867.0</td>\n",
       "      <td>4460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>SIN01R</td>\n",
       "      <td>day_8_weekday_5</td>\n",
       "      <td>273</td>\n",
       "      <td>172</td>\n",
       "      <td>6.0</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>993.0</td>\n",
       "      <td>5484.803030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>SIN01R</td>\n",
       "      <td>day_9_weekday_6</td>\n",
       "      <td>190</td>\n",
       "      <td>131</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>499.0</td>\n",
       "      <td>2581.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4132 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     destsitecode             date1  batch_cnt  route_cnt  votes     weights  \\\n",
       "0            010R  day_10_weekday_7         49         50   49.0  138.470000   \n",
       "1            010R   day_1_weekday_5        137        110   22.0  228.006667   \n",
       "2            010R   day_2_weekday_6         20         20   20.0   30.330000   \n",
       "3            010R   day_3_weekday_7         48         48   63.0   82.150000   \n",
       "4            010R   day_4_weekday_1        168        145   66.0  174.100000   \n",
       "...           ...               ...        ...        ...    ...         ...   \n",
       "4127       SIN01R   day_5_weekday_2        250        154    0.0    0.000000   \n",
       "4128       SIN01R   day_6_weekday_3        252        148   11.0  117.000000   \n",
       "4129       SIN01R   day_7_weekday_4        269        169    0.0    0.000000   \n",
       "4130       SIN01R   day_8_weekday_5        273        172    6.0  101.000000   \n",
       "4131       SIN01R   day_9_weekday_6        190        131    2.0    6.000000   \n",
       "\n",
       "      air_votes  air_weights  \n",
       "0          62.0   277.600000  \n",
       "1        3639.0  6778.520000  \n",
       "2           7.0    23.000000  \n",
       "3          77.0   223.300000  \n",
       "4        4093.0  7151.521364  \n",
       "...         ...          ...  \n",
       "4127      860.0  3797.000000  \n",
       "4128      885.0  4001.583333  \n",
       "4129      867.0  4460.000000  \n",
       "4130      993.0  5484.803030  \n",
       "4131      499.0  2581.500000  \n",
       "\n",
       "[4132 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['day_10_weekday_7', 'day_1_weekday_5', 'day_2_weekday_6',\n",
       "       'day_3_weekday_7', 'day_4_weekday_1', 'day_5_weekday_2',\n",
       "       'day_6_weekday_3', 'day_7_weekday_4', 'day_8_weekday_5',\n",
       "       'day_9_weekday_6'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta_test['batch_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-08-31'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_arr['a.report_dt'].max()\n",
    "# 日期不连续, 需要空两天.\n",
    "# 训练集训练 直接预测两天, 再作补充. 再合并测试集训练, 预测剩余4天."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11246 don"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_dest.merge(ta, \\\n",
    "#     left_on=['destsitecode', 'date1'], \n",
    "#     right_on = ['operate_zone_code', 'batch_date'],\n",
    "#     how = 'left',  validate = 'one_to_one')  .isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def od2_(od_dest):\n",
    "    od_dest['vper_ba'] = od_dest['batch_cnt'] / od_dest['votes'] \n",
    "    od_dest['vper_ro'] = od_dest['route_cnt'] / od_dest['votes'] \n",
    "    od_dest['vper_we'] = od_dest['weights']   / od_dest['votes'] \n",
    "    return od_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_(od_dest, ta, hist_arr, od_ta_his):\n",
    "    \"\"\"\n",
    "    od_dest , ta, loc, hist_arr_part\n",
    "    \"\"\"\n",
    "    od_ta = od_dest.merge(ta, \\\n",
    "        left_on=['destsitecode', 'date1'], \n",
    "        right_on = ['operate_zone_code', 'batch_date'],\n",
    "        how = 'left',  validate = 'one_to_one') \n",
    "        # task arrange lakc 267\n",
    "\n",
    "\n",
    "    od_ta_his = hist_arr.merge(\n",
    "        od_ta, \n",
    "        left_on = ['a.report_dt', 'a.zonecode'], \n",
    "        right_on = ['date1', 'destsitecode'], validate = 'one_to_one', how = 'right') \\\n",
    "            # .isna().sum()   264\n",
    "\n",
    "\n",
    "\n",
    "    od_ta_his_loc = od_ta_his.merge(loc, \\\n",
    "        left_on=['destsitecode' ], \n",
    "        right_on = ['场地代码'],\n",
    "        how = 'left')\n",
    "        #  .isna().sum() 1388\n",
    "\n",
    "    od_ta_his_loc = od_ta_his_loc.drop(['a.report_dt', 'a.zonecode','operate_zone_code','batch_date', \\\n",
    "        '场地代码','场地类型' ,'主服务业务区'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dscshap3808\\Miniconda3\\envs\\siming\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass missing_values=median as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "od_ta_his_loc.isna().sum() \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "imp = SimpleImputer('median', missing_values = np.nan )\n",
    "imp2 = KNNImputer(n_neighbors=12, weights=\"uniform\", missing_values = np.nan)\n",
    "# imp.fit_transform(od_ta_his[list(impute.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 190 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "impute = pd.DataFrame(od_ta_his_loc.isna().sum() != 0)\n",
    "impute = impute[impute[0] == True] \n",
    "for i in impute.index:\n",
    "    od_ta_his_loc[i] = od_ta_his_loc[i].astype(float)\n",
    "\n",
    "# # del loc, hist_arr  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 仅使用存在于测试集的站点.\n",
    "od_ta_his_loc = od_ta_his_loc[od_ta_his_loc['destsitecode'].isin(list(test_out['zonecode']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_ta_his_loc = od_ta_his_loc[['all_arr_waybill', 'all_arr_weight', 'simu_arr_waybill',\n",
    "#        'simu_arr_weight', 'destsitecode', 'date1', 'batch_cnt', 'route_cnt',\n",
    "#        'votes', 'weights', 'air_votes', 'air_weights']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dscshap3808\\Miniconda3\\envs\\siming\\lib\\site-packages\\pandas\\core\\frame.py:3673: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "knn imputation on missing values.\n",
    "label encoding.\n",
    "standard scale.\n",
    "\"\"\"\n",
    "od_ta_his_loc[impute.index.to_list()] = imp2.fit_transform(od_ta_his_loc[impute.index.to_list()])\n",
    "# pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.color_palette(\"rocket\", as_cmap=True)\n",
    "# def plot_distribution(col):\n",
    "#     f, axes = plt.subplots(2, 1, figsize=(7, 7), sharex=True)\n",
    "#     sns.boxplot(x = col,data = od_ta_his_loc, ax=axes[0], palette = \"rocket\")\n",
    "#     sns.kdeplot(x = col,data = od_ta_his_loc, ax=axes[1], palette = \"rocket\") \n",
    "\n",
    "# plot_distribution('all_arr_waybill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lag_feature( df, lags, cols):\n",
    "#     for col in cols:\n",
    "#         print(col)\n",
    "#         tmp = df[['destsitecode',col ]]\n",
    "#         for i in lags:\n",
    "#             shifted = tmp.copy()\n",
    "#             shifted.columns = ['destsitecode', col + \"_lag_\"+str(i)]\n",
    "#             shifted.date_block_num = shifted.date_block_num + i\n",
    "#             df = pd.merge(df, shifted, on=['destsitecode'], how='left')\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_od_part = hist_arr_part.merge(\n",
    "#     od_dest, \n",
    "#     left_on = ['a.report_dt', 'a.zonecode'], \n",
    "#     right_on = ['date1', 'destsitecode'], validate = 'one_to_one', how = 'right'); len(hist_od_part)\n",
    "\n",
    "# hist_od_part = hist_od_part.drop(['a.report_dt','a.zonecode'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del od, task_loc, hist_arr\n",
    "# del task_loc_nulled, task_loc_valued\n",
    "# # [len(task_loc), len(train), len(od)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# what a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_ta_his_loc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSCSHA~1\\AppData\\Local\\Temp/ipykernel_33900/4012905181.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  od_ta_his_loc['destsitecode'] = od_ta_his_loc['destsitecode'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "od_ta_his_loc['destsitecode'] = od_ta_his_loc['destsitecode'].astype(str)\n",
    "train_data = od_ta_his_loc\n",
    "# [od_ta_his_loc['destsitecode'] == '010W'] \n",
    "train_x = train_data.drop(['all_arr_weight', 'simu_arr_waybill','simu_arr_weight'], axis = 1)\n",
    "# train_x = train_x[['all_arr_waybill', 'date1', 'batch_cnt', 'route_cnt',\n",
    "#        'votes', 'weights', 'air_votes', 'air_weights']]\n",
    "train_x.index = pd.to_datetime(train_x['date1'])\n",
    "train_x = train_x.rename({'all_arr_waybill' : 'y' }, axis = 1)\n",
    "\n",
    "# train_x = train_x.asfreq('D')\n",
    "# train_x = train_x.rename({'all_arr_waybill' : 'y' }, axis = 1)\n",
    "cols = [i for i in train_x.columns if i not in ['y', 'date1', 'destsitecode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/310 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet:n_changepoints greater than number of observations. Using 22.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 35)\n",
      "0     24571.844017\n",
      "1     63173.078524\n",
      "2     55872.502199\n",
      "3     -2596.925231\n",
      "4     76151.176263\n",
      "5    110529.661711\n",
      "6     17680.180854\n",
      "7     55480.475989\n",
      "8    612824.860112\n",
      "9    777577.242122\n",
      "Name: yhat, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/310 [00:21<1:52:29, 21.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010RG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet:n_changepoints greater than number of observations. Using 13.\n",
      "WARNING:fbprophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
      "  0%|          | 1/310 [00:22<1:57:28, 22.81s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Initialization failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fbprophet\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, stan_init, stan_data, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstan_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\siming\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36moptimizing\u001b[1;34m(self, data, seed, init, sample_file, algorithm, verbose, as_vector, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_sampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[0mpars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_par_vector2dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'par'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_pars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_f5236004a3fd5b8429270d00efcc0cf9_4801920833298747823.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_f5236004a3fd5b8429270d00efcc0cf9_4801920833298747823.StanFit4Model._call_sampler\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_f5236004a3fd5b8429270d00efcc0cf9_4801920833298747823.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_f5236004a3fd5b8429270d00efcc0cf9_4801920833298747823._call_sampler\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Initialization failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DSCSHA~1\\AppData\\Local\\Temp/ipykernel_33900/4278429704.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m    \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProphet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m    \u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_regressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m    \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m    \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'destsitecode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'destsitecode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fbprophet\\forecaster.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, df, **kwargs)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstan_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmcmc_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstan_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[1;31m# If no changepoints were requested, replace delta with 0s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fbprophet\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, stan_init, stan_data, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m             )\n\u001b[0;32m    251\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'algorithm'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Newton'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstan_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\siming\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36moptimizing\u001b[1;34m(self, data, seed, init, sample_file, algorithm, verbose, as_vector, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mstan_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_valid_stan_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_sampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[0mpars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_par_vector2dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'par'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_pars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mas_vector\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_f5236004a3fd5b8429270d00efcc0cf9_4801920833298747823.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_f5236004a3fd5b8429270d00efcc0cf9_4801920833298747823.StanFit4Model._call_sampler\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_f5236004a3fd5b8429270d00efcc0cf9_4801920833298747823.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_f5236004a3fd5b8429270d00efcc0cf9_4801920833298747823._call_sampler\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Initialization failed."
     ]
    }
   ],
   "source": [
    "list = []\n",
    "final = pd.DataFrame()\n",
    "df_naiv = train_x.rename({'date1' : 'ds'}, axis = 1)\n",
    "# df_naiv_test = x_test.rename({'date1' : 'ds'}, axis = 1)\n",
    "site = list(df_naiv['destsitecode'].unique())\n",
    "for g in tqdm(site):\n",
    "   print(str(g))\n",
    "   group = df_naiv[df_naiv['destsitecode'] == g]\n",
    "   # x_train, x_test = temporal_train_test_split(group, train_size = .75)\n",
    "   del m\n",
    "   m = Prophet()\n",
    "   [m.add_regressor(i) for i in cols]\n",
    "   m.fit(group)\n",
    "   test = x_test[x_test['destsitecode'] == x_train['destsitecode'][0]]\n",
    "   print(test.shape)\n",
    "   print(m.predict(test)['yhat'])\n",
    "   list.extend(m.predict(test)['yhat'])\n",
    "\n",
    "   \n",
    "# future = m.make_future_dataframe(periods = 365)\n",
    "# forecast = m.predict(future)\n",
    "# forecast = forecast.rename(columns = {\n",
    "#    'yhat': 'yhat_' + g\n",
    "# })\n",
    "# final = pd.merge(final, forecast.set_index('ds'), how = 'outer', left_index = True, right_index = True)\n",
    "\n",
    "# final = final[['yhat_' + g\n",
    "#    for g in grouped.groups.keys()\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in grouped.groups:\n",
    "#    print(i)\n",
    "# grouped.get_group('010R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = m.predict(valid_group)['yhat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>destsitecode</th>\n",
       "      <th>ds</th>\n",
       "      <th>batch_cnt</th>\n",
       "      <th>route_cnt</th>\n",
       "      <th>votes</th>\n",
       "      <th>weights</th>\n",
       "      <th>air_votes</th>\n",
       "      <th>air_weights</th>\n",
       "      <th>vper_ba</th>\n",
       "      <th>...</th>\n",
       "      <th>装车卡位（13.5M）</th>\n",
       "      <th>装车卡位（9.6M）</th>\n",
       "      <th>装车卡位（7.6M）</th>\n",
       "      <th>装车卡位（5.2M）</th>\n",
       "      <th>off</th>\n",
       "      <th>onn</th>\n",
       "      <th>off_p1</th>\n",
       "      <th>off_p2</th>\n",
       "      <th>onn_p1</th>\n",
       "      <th>onn_p2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-17</th>\n",
       "      <td>86787.0</td>\n",
       "      <td>716VA</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>1217</td>\n",
       "      <td>1275</td>\n",
       "      <td>55702.0</td>\n",
       "      <td>163122.249297</td>\n",
       "      <td>4086.0</td>\n",
       "      <td>10991.250476</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.27636</td>\n",
       "      <td>58.8</td>\n",
       "      <td>3.610909</td>\n",
       "      <td>1.685091</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-18</th>\n",
       "      <td>93603.0</td>\n",
       "      <td>716VA</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>1228</td>\n",
       "      <td>1295</td>\n",
       "      <td>58354.0</td>\n",
       "      <td>167541.586897</td>\n",
       "      <td>3990.0</td>\n",
       "      <td>10494.142308</td>\n",
       "      <td>0.021044</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.27636</td>\n",
       "      <td>58.8</td>\n",
       "      <td>3.610909</td>\n",
       "      <td>1.685091</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-19</th>\n",
       "      <td>86880.0</td>\n",
       "      <td>716VA</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>1179</td>\n",
       "      <td>1256</td>\n",
       "      <td>51264.0</td>\n",
       "      <td>142605.290238</td>\n",
       "      <td>3131.0</td>\n",
       "      <td>9360.866667</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.27636</td>\n",
       "      <td>58.8</td>\n",
       "      <td>3.610909</td>\n",
       "      <td>1.685091</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-20</th>\n",
       "      <td>74955.0</td>\n",
       "      <td>716VA</td>\n",
       "      <td>2021-06-20</td>\n",
       "      <td>1106</td>\n",
       "      <td>1188</td>\n",
       "      <td>41161.0</td>\n",
       "      <td>117409.602674</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>7088.850000</td>\n",
       "      <td>0.026870</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.27636</td>\n",
       "      <td>58.8</td>\n",
       "      <td>3.610909</td>\n",
       "      <td>1.685091</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-21</th>\n",
       "      <td>78191.0</td>\n",
       "      <td>716VA</td>\n",
       "      <td>2021-06-21</td>\n",
       "      <td>1156</td>\n",
       "      <td>1237</td>\n",
       "      <td>47396.0</td>\n",
       "      <td>126828.305555</td>\n",
       "      <td>3562.0</td>\n",
       "      <td>9047.105758</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.27636</td>\n",
       "      <td>58.8</td>\n",
       "      <td>3.610909</td>\n",
       "      <td>1.685091</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27</th>\n",
       "      <td>170394.0</td>\n",
       "      <td>991W</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>1132</td>\n",
       "      <td>1261</td>\n",
       "      <td>89385.0</td>\n",
       "      <td>197033.750819</td>\n",
       "      <td>17902.0</td>\n",
       "      <td>39490.549433</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.77636</td>\n",
       "      <td>53.4</td>\n",
       "      <td>2.070578</td>\n",
       "      <td>0.911054</td>\n",
       "      <td>4.854545</td>\n",
       "      <td>2.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-28</th>\n",
       "      <td>187065.0</td>\n",
       "      <td>991W</td>\n",
       "      <td>2021-08-28</td>\n",
       "      <td>1024</td>\n",
       "      <td>1180</td>\n",
       "      <td>76602.0</td>\n",
       "      <td>160450.382720</td>\n",
       "      <td>12356.0</td>\n",
       "      <td>26192.396667</td>\n",
       "      <td>0.013368</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.77636</td>\n",
       "      <td>53.4</td>\n",
       "      <td>2.070578</td>\n",
       "      <td>0.911054</td>\n",
       "      <td>4.854545</td>\n",
       "      <td>2.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-29</th>\n",
       "      <td>157627.0</td>\n",
       "      <td>991W</td>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>1005</td>\n",
       "      <td>1151</td>\n",
       "      <td>71607.0</td>\n",
       "      <td>142345.344013</td>\n",
       "      <td>10496.0</td>\n",
       "      <td>22829.670000</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.77636</td>\n",
       "      <td>53.4</td>\n",
       "      <td>2.070578</td>\n",
       "      <td>0.911054</td>\n",
       "      <td>4.854545</td>\n",
       "      <td>2.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>176476.0</td>\n",
       "      <td>991W</td>\n",
       "      <td>2021-08-30</td>\n",
       "      <td>1130</td>\n",
       "      <td>1230</td>\n",
       "      <td>85150.0</td>\n",
       "      <td>176468.060059</td>\n",
       "      <td>16857.0</td>\n",
       "      <td>32971.769468</td>\n",
       "      <td>0.013271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.77636</td>\n",
       "      <td>53.4</td>\n",
       "      <td>2.070578</td>\n",
       "      <td>0.911054</td>\n",
       "      <td>4.854545</td>\n",
       "      <td>2.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>181772.0</td>\n",
       "      <td>991W</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1120</td>\n",
       "      <td>1217</td>\n",
       "      <td>82657.0</td>\n",
       "      <td>172315.431133</td>\n",
       "      <td>16080.0</td>\n",
       "      <td>30781.278182</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.77636</td>\n",
       "      <td>53.4</td>\n",
       "      <td>2.070578</td>\n",
       "      <td>0.911054</td>\n",
       "      <td>4.854545</td>\n",
       "      <td>2.136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6720 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   y destsitecode          ds  batch_cnt  route_cnt    votes  \\\n",
       "date1                                                                          \n",
       "2021-06-17   86787.0        716VA  2021-06-17       1217       1275  55702.0   \n",
       "2021-06-18   93603.0        716VA  2021-06-18       1228       1295  58354.0   \n",
       "2021-06-19   86880.0        716VA  2021-06-19       1179       1256  51264.0   \n",
       "2021-06-20   74955.0        716VA  2021-06-20       1106       1188  41161.0   \n",
       "2021-06-21   78191.0        716VA  2021-06-21       1156       1237  47396.0   \n",
       "...              ...          ...         ...        ...        ...      ...   \n",
       "2021-08-27  170394.0         991W  2021-08-27       1132       1261  89385.0   \n",
       "2021-08-28  187065.0         991W  2021-08-28       1024       1180  76602.0   \n",
       "2021-08-29  157627.0         991W  2021-08-29       1005       1151  71607.0   \n",
       "2021-08-30  176476.0         991W  2021-08-30       1130       1230  85150.0   \n",
       "2021-08-31  181772.0         991W  2021-08-31       1120       1217  82657.0   \n",
       "\n",
       "                  weights  air_votes   air_weights   vper_ba  ...  \\\n",
       "date1                                                         ...   \n",
       "2021-06-17  163122.249297     4086.0  10991.250476  0.021848  ...   \n",
       "2021-06-18  167541.586897     3990.0  10494.142308  0.021044  ...   \n",
       "2021-06-19  142605.290238     3131.0   9360.866667  0.022999  ...   \n",
       "2021-06-20  117409.602674     2402.0   7088.850000  0.026870  ...   \n",
       "2021-06-21  126828.305555     3562.0   9047.105758  0.024390  ...   \n",
       "...                   ...        ...           ...       ...  ...   \n",
       "2021-08-27  197033.750819    17902.0  39490.549433  0.012664  ...   \n",
       "2021-08-28  160450.382720    12356.0  26192.396667  0.013368  ...   \n",
       "2021-08-29  142345.344013    10496.0  22829.670000  0.014035  ...   \n",
       "2021-08-30  176468.060059    16857.0  32971.769468  0.013271  ...   \n",
       "2021-08-31  172315.431133    16080.0  30781.278182  0.013550  ...   \n",
       "\n",
       "            装车卡位（13.5M）  装车卡位（9.6M）  装车卡位（7.6M）  装车卡位（5.2M）       off   onn  \\\n",
       "date1                                                                         \n",
       "2021-06-17          1.0         0.0         1.0         1.0  25.27636  58.8   \n",
       "2021-06-18          1.0         0.0         1.0         1.0  25.27636  58.8   \n",
       "2021-06-19          1.0         0.0         1.0         1.0  25.27636  58.8   \n",
       "2021-06-20          1.0         0.0         1.0         1.0  25.27636  58.8   \n",
       "2021-06-21          1.0         0.0         1.0         1.0  25.27636  58.8   \n",
       "...                 ...         ...         ...         ...       ...   ...   \n",
       "2021-08-27          1.0         1.0         1.0         1.0  22.77636  53.4   \n",
       "2021-08-28          1.0         1.0         1.0         1.0  22.77636  53.4   \n",
       "2021-08-29          1.0         1.0         1.0         1.0  22.77636  53.4   \n",
       "2021-08-30          1.0         1.0         1.0         1.0  22.77636  53.4   \n",
       "2021-08-31          1.0         1.0         1.0         1.0  22.77636  53.4   \n",
       "\n",
       "              off_p1    off_p2    onn_p1  onn_p2  \n",
       "date1                                             \n",
       "2021-06-17  3.610909  1.685091  8.400000   3.920  \n",
       "2021-06-18  3.610909  1.685091  8.400000   3.920  \n",
       "2021-06-19  3.610909  1.685091  8.400000   3.920  \n",
       "2021-06-20  3.610909  1.685091  8.400000   3.920  \n",
       "2021-06-21  3.610909  1.685091  8.400000   3.920  \n",
       "...              ...       ...       ...     ...  \n",
       "2021-08-27  2.070578  0.911054  4.854545   2.136  \n",
       "2021-08-28  2.070578  0.911054  4.854545   2.136  \n",
       "2021-08-29  2.070578  0.911054  4.854545   2.136  \n",
       "2021-08-30  2.070578  0.911054  4.854545   2.136  \n",
       "2021-08-31  2.070578  0.911054  4.854545   2.136  \n",
       "\n",
       "[6720 rows x 35 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naiv_test[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from fbprophet import Prophet\n",
    "# # df = x[['CREATION_DATE_TIME_STAMP', 'qty']]\n",
    "# df_naiv = x_train \n",
    "# df_naiv = df_naiv.rename({'date1' : 'ds'}, axis = 1)\n",
    "# df_naiv_test = x_test\n",
    "# df_naiv_test = df_naiv_test.rename({'date1' : 'ds'}, axis = 1)\n",
    "# m = Prophet()\n",
    "# [m.add_regressor(i) for i in cols]\n",
    "\n",
    "# m.fit(df_naiv)\n",
    "\n",
    "# # from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# # # m.predict(x_test)\n",
    "# # mean_absolute_percentage_error(df_naiv_test['y'], m.predict(df_naiv_test)['yhat'])\n",
    "# # ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.plot_components(m.predict(df_naiv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%warning = False\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.tools import FigureFactory as FF\n",
    "\n",
    "# test_pre_p = go.Figure()\n",
    "# test_pre_p.add_trace(go.Scatter(x = test_pred['ds'],\\\n",
    "#     y = test_pred['yhat'], \n",
    "#     mode = 'markers',\n",
    "#     name = 'pred'))\n",
    "# test_pre_p.add_trace(go.Scatter(x = test_all['ds'], \\\n",
    "#     y = test_all['y'], \n",
    "#     mode = 'markers',\n",
    "#     name = 'original_out'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert data_clea.ipynb --to html --no-input --no-prompt --stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reset_index(drop = True)\n",
    "train_x['date1'] = pd.to_datetime(train_x['date1'])\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "x_train, x_test = temporal_train_test_split(train_x, train_size = .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-27 19:58:08,871] ERROR | darts.timeseries | ValueError: The time index of the provided DataArray is missing the freq attribute, and the frequency cannot be inferred.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The time index of the provided DataArray is missing the freq attribute, and the frequency cannot be inferred.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DSCSHA~1\\AppData\\Local\\Temp/ipykernel_33900/1822992607.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdarts\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m series_train = TimeSeries.from_dataframe(x_train, \n\u001b[0m\u001b[0;32m      5\u001b[0m        \u001b[0mtime_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'date1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m        value_cols ='all_arr_waybill')\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\siming\\lib\\site-packages\\darts\\timeseries.py\u001b[0m in \u001b[0;36mfrom_dataframe\u001b[1;34m(df, time_col, value_cols, fill_missing_dates, freq)\u001b[0m\n\u001b[0;32m    334\u001b[0m                           coords={time_index.name: time_index, DIMS[1]: series_df.columns})\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_xarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_missing_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_missing_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\siming\\lib\\site-packages\\darts\\timeseries.py\u001b[0m in \u001b[0;36mfrom_xarray\u001b[1;34m(xa, fill_missing_dates, freq)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;31m# Otherwise we cast to float64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxa_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\siming\\lib\\site-packages\\darts\\timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xa)\u001b[0m\n\u001b[0;32m     80\u001b[0m             self._freq: pd.DateOffset = (freq_tmp if freq_tmp is not None else\n\u001b[0;32m     81\u001b[0m                                          to_offset(self._xa.get_index(self._time_dim).inferred_freq))\n\u001b[1;32m---> 82\u001b[1;33m             raise_if(self._freq is None,\n\u001b[0m\u001b[0;32m     83\u001b[0m                      \u001b[1;34m'The time index of the provided DataArray is missing the freq attribute, and the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                      \u001b[1;34m'frequency cannot be inferred.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\siming\\lib\\site-packages\\darts\\logging.py\u001b[0m in \u001b[0;36mraise_if\u001b[1;34m(condition, message, logger)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0msatisfied\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \"\"\"\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mraise_if_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\siming\\lib\\site-packages\\darts\\logging.py\u001b[0m in \u001b[0;36mraise_if_not\u001b[1;34m(condition, message, logger)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ValueError: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The time index of the provided DataArray is missing the freq attribute, and the frequency cannot be inferred."
     ]
    }
   ],
   "source": [
    "# darts\n",
    "from darts import TimeSeries\n",
    "cols = list(x_train.columns[2:])\n",
    "series_train = TimeSeries.from_dataframe(x_train, \n",
    "       time_col = 'date1', \n",
    "       value_cols ='all_arr_waybill')\n",
    "series_test = TimeSeries.from_dataframe(x_test, \n",
    "       time_col = 'date1', \n",
    "       value_cols =  'all_arr_waybill')\n",
    "series_train_cov = TimeSeries.from_dataframe(x_train,\\\n",
    "       'ds',\n",
    "       cols)\n",
    "series_test_cov = TimeSeries.from_dataframe(x_test, \n",
    "       'ds', \n",
    "       cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_span = TimeSeries.from_dataframe(x_train.append(x_test), \\\n",
    "    'ds', \n",
    "    value_cols = 'y')\n",
    "ful_span_cov = TimeSeries.from_dataframe(x_train.append(x_test), \\\n",
    "    'ds', \n",
    "    cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LSTM_darts = RNNModel(\n",
    "    model='LSTM',\n",
    "    hidden_dim=20,\n",
    "    dropout=0,\n",
    "    batch_size=7,\n",
    "    n_epochs=5,\n",
    "    optimizer_kwargs={'lr': 1e-3},\n",
    "    model_name='lstm_RNN',\n",
    "    log_tensorboard=True,\n",
    "    random_state=42,\n",
    "    # training_length=20,\n",
    "    input_chunk_length=31,\n",
    "    force_reset=True\n",
    ")\n",
    "LSTM_darts.fit(series_train,\n",
    "             future_covariates=series_train_cov,\n",
    "            #  val_series=series_test,\n",
    "            #  val_future_covariates=series_test_cov,\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "lstm_pred_test = LSTM_darts.predict(n = 334, future_covariates = ful_span_cov).values()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47b50d2908d96196e4220cfb4e81faa93803065ea975497e7026f672c1f58470"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('siming': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
